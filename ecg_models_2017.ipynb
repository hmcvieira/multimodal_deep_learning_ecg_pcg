{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG & PCG analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\helde\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\users\\helde\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix as cm, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import itertools\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from itertools import product\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.utils import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = 'physionet2017_ecg_scalograms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p = pd.read_csv(f\"./{main_folder}/train/dataset.csv\",usecols=range(1,3))\n",
    "test_df_p = pd.read_csv(f\"./{main_folder}/test/dataset.csv\",usecols=range(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p['label']=train_df_p['label'].astype(str)\n",
    "test_df_p['label']=test_df_p['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p['group'] = train_df_p['filename'].apply(lambda x: x.split('_')[0])\n",
    "test_df_p['group'] = test_df_p['filename'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A06729_11.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A06729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A06047_4.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A06047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01326_149.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>A01326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A02351_69.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A02351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A03493_22.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>A03493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>A05868_37340.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A05868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>A05868_37341.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A05868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>A05868_37342.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A05868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>A05868_37344.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A05868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37344</th>\n",
       "      <td>A05868_37343.tiff</td>\n",
       "      <td>0</td>\n",
       "      <td>A05868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37345 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename label   group\n",
       "0         A06729_11.tiff     0  A06729\n",
       "1          A06047_4.tiff     0  A06047\n",
       "2        A01326_149.tiff     1  A01326\n",
       "3         A02351_69.tiff     0  A02351\n",
       "4         A03493_22.tiff     1  A03493\n",
       "...                  ...   ...     ...\n",
       "37340  A05868_37340.tiff     0  A05868\n",
       "37341  A05868_37341.tiff     0  A05868\n",
       "37342  A05868_37342.tiff     0  A05868\n",
       "37343  A05868_37344.tiff     0  A05868\n",
       "37344  A05868_37343.tiff     0  A05868\n",
       "\n",
       "[37345 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_p = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "val_datagen_p = ImageDataGenerator(preprocessing_function= preprocess_input)\n",
    "\n",
    "test_datagen_p = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model creation function\n",
    "def create_model(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)  # Add Global Average Pooling\n",
    "    x = Dense(neurons, activation='relu')(x)  # Add a fully connected layer\n",
    "    x = Dropout(dropout) (x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Replace softmax with sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['Accuracy'])\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,926,209\n",
      "Trainable params: 3,211,521\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model creation function\n",
    "def create_model_finetune(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    base_model.trainable = True\n",
    "    num_layers = len(base_model.layers)\n",
    "    num_layers_fine_tune = 8\n",
    "    for model_layer in base_model.layers[:num_layers - num_layers_fine_tune]:\n",
    "        model_layer.trainable = False\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    x = base_model.output\n",
    "    \n",
    "    \n",
    "    x = Flatten()(x)  # Add Global Average Pooling\n",
    "    x = Dense(neurons, activation='relu')(x)  # Add a fully connected layer\n",
    "    x = Dropout(dropout) (x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Replace softmax with sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "        \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['Accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,926,209\n",
      "Trainable params: 16,190,721\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, train_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.train_data = train_data\n",
    "        self.val_f1_scores = []\n",
    "        self.train_f1_scores = []\n",
    "        self.val_accuracies = []\n",
    "        self.train_accuracies = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_val, y_val = self.validation_data, self.validation_data.classes\n",
    "        X_train, y_train = self.train_data, self.train_data.classes\n",
    "\n",
    "        y_pred_val = self.model.predict(X_val)\n",
    "        y_pred_rounded_val = np.round(y_pred_val)  # Round predictions to binary values\n",
    "        y_pred_train = self.model.predict(X_train)\n",
    "        y_pred_rounded_train = np.round(y_pred_train)  # Round predictions to binary values\n",
    "        \n",
    "        macro_f1_val = f1_score(y_val, y_pred_rounded_val, average='macro')\n",
    "        self.val_f1_scores.append(macro_f1_val)\n",
    "        \n",
    "        macro_f1_train = f1_score(y_train, y_pred_rounded_train, average='macro')\n",
    "        self.train_f1_scores.append(macro_f1_train)\n",
    "        \n",
    "        acc_val = accuracy_score(y_val, y_pred_rounded_val)\n",
    "        self.val_accuracies.append(acc_val)\n",
    "        acc_train = accuracy_score(y_train, y_pred_rounded_train)\n",
    "        self.train_accuracies.append(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [ 32],\n",
    "    'epochs': [ 30],\n",
    "    'optimizer': ['adam'],\n",
    "    'learning_rate': [ 0.000001],\n",
    "    'dropout':[ 0.5],\n",
    "    'neurons':[128],\n",
    "    'class_weights':[True]\n",
    "}\n",
    "\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Define f1_macro scorer\n",
    "#f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(generator, model):\n",
    "    y_true = generator.classes\n",
    "    predictions = model.predict(generator)\n",
    "    threshold = 0.5\n",
    "    predicted_classes = (predictions > threshold).astype(int)\n",
    "    \n",
    "    f1_macro_value = f1_score(y_true,predicted_classes, average='binary' )\n",
    "    acc = accuracy_score(y_true, predicted_classes)\n",
    "    auc = roc_auc_score(y_true, predictions) \n",
    "    precision = precision_score(y_true, predicted_classes)\n",
    "    recall = recall_score(y_true, predicted_classes)\n",
    "    return f1_macro_value, acc, auc, precision, recall, predictions, y_true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': True}\n",
      "-----------------FOLD 0-----------------\n",
      "Found 29929 validated image filenames belonging to 2 classes.\n",
      "Found 7416 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "936/936 [==============================] - 281s 296ms/step - loss: 1.9781 - Accuracy: 0.5605 - val_loss: 0.6787 - val_Accuracy: 0.6239\n",
      "Epoch 2/30\n",
      "936/936 [==============================] - 271s 290ms/step - loss: 0.7500 - Accuracy: 0.6112 - val_loss: 0.5784 - val_Accuracy: 0.6977\n",
      "Epoch 3/30\n",
      "936/936 [==============================] - 278s 297ms/step - loss: 0.6436 - Accuracy: 0.6502 - val_loss: 0.5607 - val_Accuracy: 0.7121\n",
      "Epoch 4/30\n",
      "936/936 [==============================] - 274s 293ms/step - loss: 0.6019 - Accuracy: 0.6847 - val_loss: 0.5585 - val_Accuracy: 0.7226\n",
      "Epoch 5/30\n",
      "936/936 [==============================] - 296s 316ms/step - loss: 0.5727 - Accuracy: 0.7102 - val_loss: 0.5471 - val_Accuracy: 0.7311\n",
      "Epoch 6/30\n",
      "936/936 [==============================] - 284s 303ms/step - loss: 0.5503 - Accuracy: 0.7322 - val_loss: 0.5184 - val_Accuracy: 0.7543\n",
      "Epoch 7/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.5323 - Accuracy: 0.7437 - val_loss: 0.5088 - val_Accuracy: 0.7597\n",
      "Epoch 8/30\n",
      "936/936 [==============================] - 273s 292ms/step - loss: 0.5165 - Accuracy: 0.7588 - val_loss: 0.5248 - val_Accuracy: 0.7551\n",
      "Epoch 9/30\n",
      "936/936 [==============================] - 273s 292ms/step - loss: 0.4994 - Accuracy: 0.7675 - val_loss: 0.4740 - val_Accuracy: 0.7793\n",
      "Epoch 10/30\n",
      "936/936 [==============================] - 281s 300ms/step - loss: 0.4895 - Accuracy: 0.7780 - val_loss: 0.4692 - val_Accuracy: 0.7851\n",
      "Epoch 11/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.4782 - Accuracy: 0.7865 - val_loss: 0.4592 - val_Accuracy: 0.7888\n",
      "Epoch 12/30\n",
      "936/936 [==============================] - 282s 301ms/step - loss: 0.4694 - Accuracy: 0.7889 - val_loss: 0.4931 - val_Accuracy: 0.7786\n",
      "Epoch 13/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.4613 - Accuracy: 0.7935 - val_loss: 0.4667 - val_Accuracy: 0.7906\n",
      "Epoch 14/30\n",
      "936/936 [==============================] - 272s 290ms/step - loss: 0.4541 - Accuracy: 0.7990 - val_loss: 0.4602 - val_Accuracy: 0.7938\n",
      "Epoch 15/30\n",
      "936/936 [==============================] - 280s 300ms/step - loss: 0.4469 - Accuracy: 0.8039 - val_loss: 0.5106 - val_Accuracy: 0.7674\n",
      "Epoch 16/30\n",
      "936/936 [==============================] - 286s 306ms/step - loss: 0.4366 - Accuracy: 0.8089 - val_loss: 0.4720 - val_Accuracy: 0.7956\n",
      "Epoch 17/30\n",
      "936/936 [==============================] - 271s 290ms/step - loss: 0.4331 - Accuracy: 0.8120 - val_loss: 0.4664 - val_Accuracy: 0.7961\n",
      "Epoch 18/30\n",
      "936/936 [==============================] - 292s 312ms/step - loss: 0.4277 - Accuracy: 0.8146 - val_loss: 0.4730 - val_Accuracy: 0.7950\n",
      "Epoch 19/30\n",
      "936/936 [==============================] - 273s 292ms/step - loss: 0.4178 - Accuracy: 0.8195 - val_loss: 0.4576 - val_Accuracy: 0.7971\n",
      "Epoch 20/30\n",
      "936/936 [==============================] - 271s 290ms/step - loss: 0.4167 - Accuracy: 0.8232 - val_loss: 0.4652 - val_Accuracy: 0.7984\n",
      "Epoch 21/30\n",
      "936/936 [==============================] - 276s 295ms/step - loss: 0.4066 - Accuracy: 0.8263 - val_loss: 0.4637 - val_Accuracy: 0.7996\n",
      "Epoch 22/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.4002 - Accuracy: 0.8310 - val_loss: 0.4621 - val_Accuracy: 0.8010\n",
      "Epoch 23/30\n",
      "936/936 [==============================] - 274s 293ms/step - loss: 0.3959 - Accuracy: 0.8316 - val_loss: 0.4813 - val_Accuracy: 0.7913\n",
      "Epoch 24/30\n",
      "936/936 [==============================] - 274s 293ms/step - loss: 0.3888 - Accuracy: 0.8368 - val_loss: 0.4510 - val_Accuracy: 0.8056\n",
      "Epoch 25/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.3826 - Accuracy: 0.8377 - val_loss: 0.4557 - val_Accuracy: 0.8022\n",
      "Epoch 26/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.3760 - Accuracy: 0.8424 - val_loss: 0.4521 - val_Accuracy: 0.8065\n",
      "Epoch 27/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.3735 - Accuracy: 0.8431 - val_loss: 0.4697 - val_Accuracy: 0.7980\n",
      "Epoch 28/30\n",
      "936/936 [==============================] - 274s 293ms/step - loss: 0.3653 - Accuracy: 0.8477 - val_loss: 0.4820 - val_Accuracy: 0.7890\n",
      "Epoch 29/30\n",
      "936/936 [==============================] - 271s 289ms/step - loss: 0.3610 - Accuracy: 0.8516 - val_loss: 0.4547 - val_Accuracy: 0.8061\n",
      "Epoch 30/30\n",
      "936/936 [==============================] - 275s 294ms/step - loss: 0.3516 - Accuracy: 0.8552 - val_loss: 0.4703 - val_Accuracy: 0.8006\n",
      "936/936 [==============================] - 164s 175ms/step\n",
      "232/232 [==============================] - 42s 180ms/step\n",
      "0.8423299786520281 0.8790804904941696 0.943265511688457 0.8671510584858271 0.8188903007200339\n",
      "0.7485976542580318 0.8005663430420712 0.8595184836355075 0.767514813523876 0.7305905773059058\n",
      "{'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': True}\n",
      "-----------------FOLD 1-----------------\n",
      "Found 29856 validated image filenames belonging to 2 classes.\n",
      "Found 7489 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "933/933 [==============================] - 276s 295ms/step - loss: 1.8623 - Accuracy: 0.5657 - val_loss: 0.6920 - val_Accuracy: 0.6407\n",
      "Epoch 2/30\n",
      "933/933 [==============================] - 269s 289ms/step - loss: 0.7634 - Accuracy: 0.6142 - val_loss: 0.5987 - val_Accuracy: 0.6909\n",
      "Epoch 3/30\n",
      "933/933 [==============================] - 272s 292ms/step - loss: 0.6432 - Accuracy: 0.6591 - val_loss: 0.5588 - val_Accuracy: 0.7319\n",
      "Epoch 4/30\n",
      "933/933 [==============================] - 269s 289ms/step - loss: 0.6016 - Accuracy: 0.6863 - val_loss: 0.5391 - val_Accuracy: 0.7480\n",
      "Epoch 5/30\n",
      "933/933 [==============================] - 273s 292ms/step - loss: 0.5651 - Accuracy: 0.7200 - val_loss: 0.5216 - val_Accuracy: 0.7588\n",
      "Epoch 6/30\n",
      "933/933 [==============================] - 271s 290ms/step - loss: 0.5423 - Accuracy: 0.7369 - val_loss: 0.5205 - val_Accuracy: 0.7622\n",
      "Epoch 7/30\n",
      "933/933 [==============================] - 269s 289ms/step - loss: 0.5244 - Accuracy: 0.7501 - val_loss: 0.5251 - val_Accuracy: 0.7562\n",
      "Epoch 8/30\n",
      "933/933 [==============================] - 270s 289ms/step - loss: 0.5119 - Accuracy: 0.7582 - val_loss: 0.5328 - val_Accuracy: 0.7554\n",
      "Epoch 9/30\n",
      "933/933 [==============================] - 287s 307ms/step - loss: 0.4960 - Accuracy: 0.7712 - val_loss: 0.4954 - val_Accuracy: 0.7774\n",
      "Epoch 10/30\n",
      "933/933 [==============================] - 270s 290ms/step - loss: 0.4855 - Accuracy: 0.7777 - val_loss: 0.4873 - val_Accuracy: 0.7856\n",
      "Epoch 11/30\n",
      "933/933 [==============================] - 276s 296ms/step - loss: 0.4738 - Accuracy: 0.7854 - val_loss: 0.4815 - val_Accuracy: 0.7893\n",
      "Epoch 12/30\n",
      "933/933 [==============================] - 278s 297ms/step - loss: 0.4617 - Accuracy: 0.7909 - val_loss: 0.4912 - val_Accuracy: 0.7823\n",
      "Epoch 13/30\n",
      "933/933 [==============================] - 272s 292ms/step - loss: 0.4544 - Accuracy: 0.7978 - val_loss: 0.4805 - val_Accuracy: 0.7896\n",
      "Epoch 14/30\n",
      "933/933 [==============================] - 271s 290ms/step - loss: 0.4451 - Accuracy: 0.8035 - val_loss: 0.5084 - val_Accuracy: 0.7819\n",
      "Epoch 15/30\n",
      "933/933 [==============================] - 271s 291ms/step - loss: 0.4402 - Accuracy: 0.8065 - val_loss: 0.4861 - val_Accuracy: 0.7880\n",
      "Epoch 16/30\n",
      "933/933 [==============================] - 270s 290ms/step - loss: 0.4305 - Accuracy: 0.8133 - val_loss: 0.4912 - val_Accuracy: 0.7866\n",
      "Epoch 17/30\n",
      "933/933 [==============================] - 280s 300ms/step - loss: 0.4219 - Accuracy: 0.8155 - val_loss: 0.4937 - val_Accuracy: 0.7868\n",
      "Epoch 18/30\n",
      "933/933 [==============================] - 271s 290ms/step - loss: 0.4160 - Accuracy: 0.8217 - val_loss: 0.4709 - val_Accuracy: 0.7977\n",
      "Epoch 19/30\n",
      "933/933 [==============================] - 275s 294ms/step - loss: 0.4072 - Accuracy: 0.8257 - val_loss: 0.4806 - val_Accuracy: 0.7902\n",
      "Epoch 20/30\n",
      "933/933 [==============================] - 274s 293ms/step - loss: 0.4036 - Accuracy: 0.8256 - val_loss: 0.4892 - val_Accuracy: 0.7893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "933/933 [==============================] - 270s 289ms/step - loss: 0.3946 - Accuracy: 0.8328 - val_loss: 0.4798 - val_Accuracy: 0.7933\n",
      "Epoch 22/30\n",
      "933/933 [==============================] - 269s 288ms/step - loss: 0.3877 - Accuracy: 0.8356 - val_loss: 0.4885 - val_Accuracy: 0.7926\n",
      "Epoch 23/30\n",
      "933/933 [==============================] - 274s 293ms/step - loss: 0.3857 - Accuracy: 0.8371 - val_loss: 0.4826 - val_Accuracy: 0.7953\n",
      "Epoch 24/30\n",
      "933/933 [==============================] - 276s 296ms/step - loss: 0.3747 - Accuracy: 0.8431 - val_loss: 0.4856 - val_Accuracy: 0.7936\n",
      "Epoch 25/30\n",
      "933/933 [==============================] - 302s 324ms/step - loss: 0.3702 - Accuracy: 0.8427 - val_loss: 0.4959 - val_Accuracy: 0.7885\n",
      "Epoch 26/30\n",
      "933/933 [==============================] - 274s 294ms/step - loss: 0.3627 - Accuracy: 0.8465 - val_loss: 0.4863 - val_Accuracy: 0.7956\n",
      "Epoch 27/30\n",
      "933/933 [==============================] - 271s 291ms/step - loss: 0.3570 - Accuracy: 0.8508 - val_loss: 0.5069 - val_Accuracy: 0.7839\n",
      "Epoch 28/30\n",
      "933/933 [==============================] - 274s 294ms/step - loss: 0.3493 - Accuracy: 0.8551 - val_loss: 0.4746 - val_Accuracy: 0.8016\n",
      "Epoch 29/30\n",
      "933/933 [==============================] - 282s 302ms/step - loss: 0.3415 - Accuracy: 0.8581 - val_loss: 0.4861 - val_Accuracy: 0.7974\n",
      "Epoch 30/30\n",
      "933/933 [==============================] - 284s 305ms/step - loss: 0.3391 - Accuracy: 0.8601 - val_loss: 0.4746 - val_Accuracy: 0.8022\n",
      "933/933 [==============================] - 164s 173ms/step\n",
      "235/235 [==============================] - 41s 174ms/step\n",
      "0.8532537103714762 0.8880627009646302 0.9527783804841458 0.8955664116508434 0.8147589098532495\n",
      "0.7314596554850408 0.8022432901588997 0.844092464015076 0.7695536054940862 0.6969592259847961\n",
      "{'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': True}\n",
      "-----------------FOLD 2-----------------\n",
      "Found 29858 validated image filenames belonging to 2 classes.\n",
      "Found 7487 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "934/934 [==============================] - 280s 294ms/step - loss: 1.9160 - Accuracy: 0.5519 - val_loss: 0.6921 - val_Accuracy: 0.6286\n",
      "Epoch 2/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.7505 - Accuracy: 0.6168 - val_loss: 0.6387 - val_Accuracy: 0.6426\n",
      "Epoch 3/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.6399 - Accuracy: 0.6569 - val_loss: 0.5808 - val_Accuracy: 0.6929\n",
      "Epoch 4/30\n",
      "934/934 [==============================] - 273s 292ms/step - loss: 0.5993 - Accuracy: 0.6844 - val_loss: 0.5781 - val_Accuracy: 0.6931\n",
      "Epoch 5/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.5694 - Accuracy: 0.7099 - val_loss: 0.5490 - val_Accuracy: 0.7221\n",
      "Epoch 6/30\n",
      "934/934 [==============================] - 276s 295ms/step - loss: 0.5467 - Accuracy: 0.7262 - val_loss: 0.5438 - val_Accuracy: 0.7270\n",
      "Epoch 7/30\n",
      "934/934 [==============================] - 300s 321ms/step - loss: 0.5334 - Accuracy: 0.7442 - val_loss: 0.5325 - val_Accuracy: 0.7402\n",
      "Epoch 8/30\n",
      "934/934 [==============================] - 274s 293ms/step - loss: 0.5185 - Accuracy: 0.7554 - val_loss: 0.5505 - val_Accuracy: 0.7195\n",
      "Epoch 9/30\n",
      "934/934 [==============================] - 273s 293ms/step - loss: 0.5055 - Accuracy: 0.7604 - val_loss: 0.5345 - val_Accuracy: 0.7350\n",
      "Epoch 10/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.4905 - Accuracy: 0.7737 - val_loss: 0.5171 - val_Accuracy: 0.7525\n",
      "Epoch 11/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4822 - Accuracy: 0.7811 - val_loss: 0.5091 - val_Accuracy: 0.7625\n",
      "Epoch 12/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4719 - Accuracy: 0.7877 - val_loss: 0.5154 - val_Accuracy: 0.7599\n",
      "Epoch 13/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4601 - Accuracy: 0.7929 - val_loss: 0.4897 - val_Accuracy: 0.7732\n",
      "Epoch 14/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4520 - Accuracy: 0.7998 - val_loss: 0.4931 - val_Accuracy: 0.7727\n",
      "Epoch 15/30\n",
      "934/934 [==============================] - 282s 302ms/step - loss: 0.4443 - Accuracy: 0.8044 - val_loss: 0.5013 - val_Accuracy: 0.7649\n",
      "Epoch 16/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4381 - Accuracy: 0.8079 - val_loss: 0.5000 - val_Accuracy: 0.7681\n",
      "Epoch 17/30\n",
      "934/934 [==============================] - 277s 296ms/step - loss: 0.4251 - Accuracy: 0.8146 - val_loss: 0.4917 - val_Accuracy: 0.7759\n",
      "Epoch 18/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.4205 - Accuracy: 0.8189 - val_loss: 0.5247 - val_Accuracy: 0.7440\n",
      "Epoch 19/30\n",
      "934/934 [==============================] - 276s 296ms/step - loss: 0.4124 - Accuracy: 0.8244 - val_loss: 0.5023 - val_Accuracy: 0.7645\n",
      "Epoch 20/30\n",
      "934/934 [==============================] - 312s 334ms/step - loss: 0.4051 - Accuracy: 0.8260 - val_loss: 0.4723 - val_Accuracy: 0.7848\n",
      "Epoch 21/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.3996 - Accuracy: 0.8303 - val_loss: 0.4854 - val_Accuracy: 0.7755\n",
      "Epoch 22/30\n",
      "934/934 [==============================] - 283s 303ms/step - loss: 0.3905 - Accuracy: 0.8333 - val_loss: 0.4707 - val_Accuracy: 0.7860\n",
      "Epoch 23/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.3839 - Accuracy: 0.8367 - val_loss: 0.4814 - val_Accuracy: 0.7795\n",
      "Epoch 24/30\n",
      "934/934 [==============================] - 275s 295ms/step - loss: 0.3792 - Accuracy: 0.8383 - val_loss: 0.4722 - val_Accuracy: 0.7902\n",
      "Epoch 25/30\n",
      "934/934 [==============================] - 275s 294ms/step - loss: 0.3703 - Accuracy: 0.8450 - val_loss: 0.4714 - val_Accuracy: 0.7891\n",
      "Epoch 26/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.3664 - Accuracy: 0.8458 - val_loss: 0.4974 - val_Accuracy: 0.7751\n",
      "Epoch 27/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.3592 - Accuracy: 0.8500 - val_loss: 0.4965 - val_Accuracy: 0.7748\n",
      "Epoch 28/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.3511 - Accuracy: 0.8560 - val_loss: 0.4770 - val_Accuracy: 0.7892\n",
      "Epoch 29/30\n",
      "934/934 [==============================] - 275s 294ms/step - loss: 0.3479 - Accuracy: 0.8568 - val_loss: 0.4786 - val_Accuracy: 0.7844\n",
      "Epoch 30/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.3382 - Accuracy: 0.8606 - val_loss: 0.5334 - val_Accuracy: 0.7514\n",
      "934/934 [==============================] - 165s 168ms/step\n",
      "234/234 [==============================] - 39s 168ms/step\n",
      "0.8363367454170396 0.8591667224864358 0.9473066281413401 0.7795109918014946 0.9020990764063812\n",
      "0.7089003597684967 0.7514358220916255 0.8374619539156362 0.6504018369690011 0.7789618425575799\n",
      "{'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': True}\n",
      "-----------------FOLD 3-----------------\n",
      "Found 29857 validated image filenames belonging to 2 classes.\n",
      "Found 7488 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "934/934 [==============================] - 316s 329ms/step - loss: 1.7687 - Accuracy: 0.5680 - val_loss: 0.6800 - val_Accuracy: 0.6413\n",
      "Epoch 2/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.7519 - Accuracy: 0.6193 - val_loss: 0.5962 - val_Accuracy: 0.6878\n",
      "Epoch 3/30\n",
      "934/934 [==============================] - 280s 300ms/step - loss: 0.6409 - Accuracy: 0.6599 - val_loss: 0.5703 - val_Accuracy: 0.7146\n",
      "Epoch 4/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.5974 - Accuracy: 0.6892 - val_loss: 0.5544 - val_Accuracy: 0.7306\n",
      "Epoch 5/30\n",
      "934/934 [==============================] - 272s 291ms/step - loss: 0.5696 - Accuracy: 0.7131 - val_loss: 0.5376 - val_Accuracy: 0.7456\n",
      "Epoch 6/30\n",
      "934/934 [==============================] - 289s 310ms/step - loss: 0.5475 - Accuracy: 0.7304 - val_loss: 0.5608 - val_Accuracy: 0.7241\n",
      "Epoch 7/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.5334 - Accuracy: 0.7411 - val_loss: 0.5385 - val_Accuracy: 0.7428\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 276s 295ms/step - loss: 0.5160 - Accuracy: 0.7545 - val_loss: 0.5071 - val_Accuracy: 0.7679\n",
      "Epoch 9/30\n",
      "934/934 [==============================] - 275s 294ms/step - loss: 0.5012 - Accuracy: 0.7677 - val_loss: 0.5348 - val_Accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.4886 - Accuracy: 0.7731 - val_loss: 0.4968 - val_Accuracy: 0.7766\n",
      "Epoch 11/30\n",
      "934/934 [==============================] - 273s 292ms/step - loss: 0.4786 - Accuracy: 0.7813 - val_loss: 0.5142 - val_Accuracy: 0.7675\n",
      "Epoch 12/30\n",
      "934/934 [==============================] - 273s 292ms/step - loss: 0.4661 - Accuracy: 0.7927 - val_loss: 0.5185 - val_Accuracy: 0.7600\n",
      "Epoch 13/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4594 - Accuracy: 0.7957 - val_loss: 0.5143 - val_Accuracy: 0.7674\n",
      "Epoch 14/30\n",
      "934/934 [==============================] - 279s 299ms/step - loss: 0.4481 - Accuracy: 0.7992 - val_loss: 0.5003 - val_Accuracy: 0.7704\n",
      "Epoch 15/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4385 - Accuracy: 0.8076 - val_loss: 0.4831 - val_Accuracy: 0.7804\n",
      "Epoch 16/30\n",
      "934/934 [==============================] - 311s 333ms/step - loss: 0.4328 - Accuracy: 0.8091 - val_loss: 0.4857 - val_Accuracy: 0.7807\n",
      "Epoch 17/30\n",
      "934/934 [==============================] - 276s 296ms/step - loss: 0.4251 - Accuracy: 0.8181 - val_loss: 0.4893 - val_Accuracy: 0.7784\n",
      "Epoch 18/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4168 - Accuracy: 0.8180 - val_loss: 0.4806 - val_Accuracy: 0.7853\n",
      "Epoch 19/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4123 - Accuracy: 0.8228 - val_loss: 0.4954 - val_Accuracy: 0.7768\n",
      "Epoch 20/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.4040 - Accuracy: 0.8287 - val_loss: 0.5081 - val_Accuracy: 0.7700\n",
      "Epoch 21/30\n",
      "934/934 [==============================] - 284s 304ms/step - loss: 0.3974 - Accuracy: 0.8316 - val_loss: 0.5054 - val_Accuracy: 0.7690\n",
      "Epoch 22/30\n",
      "934/934 [==============================] - 273s 292ms/step - loss: 0.3927 - Accuracy: 0.8327 - val_loss: 0.4835 - val_Accuracy: 0.7817\n",
      "Epoch 23/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.3846 - Accuracy: 0.8379 - val_loss: 0.4877 - val_Accuracy: 0.7826\n",
      "Epoch 24/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.3781 - Accuracy: 0.8393 - val_loss: 0.4815 - val_Accuracy: 0.7878\n",
      "Epoch 25/30\n",
      "934/934 [==============================] - 271s 290ms/step - loss: 0.3724 - Accuracy: 0.8448 - val_loss: 0.4928 - val_Accuracy: 0.7799\n",
      "Epoch 26/30\n",
      "934/934 [==============================] - 272s 291ms/step - loss: 0.3632 - Accuracy: 0.8476 - val_loss: 0.4831 - val_Accuracy: 0.7898\n",
      "Epoch 27/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.3605 - Accuracy: 0.8506 - val_loss: 0.4849 - val_Accuracy: 0.7875\n",
      "Epoch 28/30\n",
      "934/934 [==============================] - 284s 304ms/step - loss: 0.3526 - Accuracy: 0.8540 - val_loss: 0.5183 - val_Accuracy: 0.7656\n",
      "Epoch 29/30\n",
      "934/934 [==============================] - 272s 292ms/step - loss: 0.3470 - Accuracy: 0.8559 - val_loss: 0.5117 - val_Accuracy: 0.7706\n",
      "Epoch 30/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.3395 - Accuracy: 0.8605 - val_loss: 0.5111 - val_Accuracy: 0.7688\n",
      "934/934 [==============================] - 171s 179ms/step\n",
      "234/234 [==============================] - 39s 167ms/step\n",
      "0.8518408676863111 0.8828750376796061 0.948858211945675 0.8513719512195121 0.8523103009749894\n",
      "0.7151555043607042 0.7688301282051282 0.8308556192040735 0.7117589256469047 0.718584656084656\n",
      "{'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': True}\n",
      "-----------------FOLD 4-----------------\n",
      "Found 29880 validated image filenames belonging to 2 classes.\n",
      "Found 7465 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "934/934 [==============================] - 276s 291ms/step - loss: 1.8694 - Accuracy: 0.5644 - val_loss: 0.6376 - val_Accuracy: 0.6607\n",
      "Epoch 2/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.7227 - Accuracy: 0.6246 - val_loss: 0.5762 - val_Accuracy: 0.7027\n",
      "Epoch 3/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.6384 - Accuracy: 0.6538 - val_loss: 0.5795 - val_Accuracy: 0.7072\n",
      "Epoch 4/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.6018 - Accuracy: 0.6800 - val_loss: 0.5414 - val_Accuracy: 0.7374\n",
      "Epoch 5/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.5821 - Accuracy: 0.6970 - val_loss: 0.5311 - val_Accuracy: 0.7488\n",
      "Epoch 6/30\n",
      "934/934 [==============================] - 271s 291ms/step - loss: 0.5579 - Accuracy: 0.7213 - val_loss: 0.5350 - val_Accuracy: 0.7431\n",
      "Epoch 7/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.5431 - Accuracy: 0.7359 - val_loss: 0.5312 - val_Accuracy: 0.7461\n",
      "Epoch 8/30\n",
      "934/934 [==============================] - 269s 287ms/step - loss: 0.5256 - Accuracy: 0.7488 - val_loss: 0.5396 - val_Accuracy: 0.7354\n",
      "Epoch 9/30\n",
      "934/934 [==============================] - 272s 291ms/step - loss: 0.5115 - Accuracy: 0.7586 - val_loss: 0.4751 - val_Accuracy: 0.7873\n",
      "Epoch 10/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.4967 - Accuracy: 0.7678 - val_loss: 0.4951 - val_Accuracy: 0.7796\n",
      "Epoch 11/30\n",
      "934/934 [==============================] - 272s 291ms/step - loss: 0.4833 - Accuracy: 0.7773 - val_loss: 0.4674 - val_Accuracy: 0.7962\n",
      "Epoch 12/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.4738 - Accuracy: 0.7849 - val_loss: 0.4695 - val_Accuracy: 0.7949\n",
      "Epoch 13/30\n",
      "934/934 [==============================] - 275s 294ms/step - loss: 0.4653 - Accuracy: 0.7890 - val_loss: 0.4951 - val_Accuracy: 0.7724\n",
      "Epoch 14/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.4600 - Accuracy: 0.7946 - val_loss: 0.4624 - val_Accuracy: 0.7969\n",
      "Epoch 15/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.4457 - Accuracy: 0.8025 - val_loss: 0.4779 - val_Accuracy: 0.7857\n",
      "Epoch 16/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.4400 - Accuracy: 0.8061 - val_loss: 0.4454 - val_Accuracy: 0.8129\n",
      "Epoch 17/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4348 - Accuracy: 0.8096 - val_loss: 0.4563 - val_Accuracy: 0.8012\n",
      "Epoch 18/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.4268 - Accuracy: 0.8140 - val_loss: 0.4761 - val_Accuracy: 0.7887\n",
      "Epoch 19/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.4185 - Accuracy: 0.8215 - val_loss: 0.4445 - val_Accuracy: 0.8113\n",
      "Epoch 20/30\n",
      "934/934 [==============================] - 274s 294ms/step - loss: 0.4135 - Accuracy: 0.8204 - val_loss: 0.4542 - val_Accuracy: 0.8056\n",
      "Epoch 21/30\n",
      "934/934 [==============================] - 269s 288ms/step - loss: 0.4031 - Accuracy: 0.8284 - val_loss: 0.4512 - val_Accuracy: 0.8066\n",
      "Epoch 22/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.3982 - Accuracy: 0.8290 - val_loss: 0.4500 - val_Accuracy: 0.8042\n",
      "Epoch 23/30\n",
      "934/934 [==============================] - 274s 293ms/step - loss: 0.3904 - Accuracy: 0.8354 - val_loss: 0.4427 - val_Accuracy: 0.8146\n",
      "Epoch 24/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.3840 - Accuracy: 0.8398 - val_loss: 0.4541 - val_Accuracy: 0.8027\n",
      "Epoch 25/30\n",
      "934/934 [==============================] - 290s 311ms/step - loss: 0.3766 - Accuracy: 0.8400 - val_loss: 0.4611 - val_Accuracy: 0.7997\n",
      "Epoch 26/30\n",
      "934/934 [==============================] - 271s 291ms/step - loss: 0.3742 - Accuracy: 0.8444 - val_loss: 0.4538 - val_Accuracy: 0.8060\n",
      "Epoch 27/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.3644 - Accuracy: 0.8488 - val_loss: 0.4517 - val_Accuracy: 0.8078\n",
      "Epoch 28/30\n",
      "934/934 [==============================] - 268s 287ms/step - loss: 0.3606 - Accuracy: 0.8497 - val_loss: 0.4597 - val_Accuracy: 0.8059\n",
      "Epoch 29/30\n",
      "934/934 [==============================] - 270s 289ms/step - loss: 0.3523 - Accuracy: 0.8527 - val_loss: 0.4489 - val_Accuracy: 0.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "934/934 [==============================] - 274s 293ms/step - loss: 0.3470 - Accuracy: 0.8545 - val_loss: 0.4593 - val_Accuracy: 0.8086\n",
      "934/934 [==============================] - 176s 187ms/step\n",
      "234/234 [==============================] - 41s 176ms/step\n",
      "0.8481726111845002 0.8846050870147256 0.9483435632820985 0.8860980771000092 0.813360358077865\n",
      "0.749605747327843 0.8085733422638982 0.8512949805145616 0.783803591058996 0.7182672934855607\n",
      "                                              params  fold_number  \\\n",
      "0  {'batch_size': 32, 'epochs': 30, 'optimizer': ...            1   \n",
      "1  {'batch_size': 32, 'epochs': 30, 'optimizer': ...            2   \n",
      "2  {'batch_size': 32, 'epochs': 30, 'optimizer': ...            3   \n",
      "3  {'batch_size': 32, 'epochs': 30, 'optimizer': ...            4   \n",
      "4  {'batch_size': 32, 'epochs': 30, 'optimizer': ...            5   \n",
      "\n",
      "                                                loss  \\\n",
      "0  [1.9781194925308228, 0.7500041723251343, 0.643...   \n",
      "1  [1.8622928857803345, 0.7634438872337341, 0.643...   \n",
      "2  [1.915986180305481, 0.7504754662513733, 0.6399...   \n",
      "3  [1.7686793804168701, 0.7519109845161438, 0.640...   \n",
      "4  [1.8694206476211548, 0.7227396368980408, 0.638...   \n",
      "\n",
      "                                           acc_train  \\\n",
      "0  [0.5605265498161316, 0.611213207244873, 0.6502...   \n",
      "1  [0.5656819343566895, 0.6142483949661255, 0.659...   \n",
      "2  [0.5519458651542664, 0.6168196201324463, 0.656...   \n",
      "3  [0.5680075287818909, 0.6192517876625061, 0.659...   \n",
      "4  [0.5643573999404907, 0.6245983839035034, 0.653...   \n",
      "\n",
      "                                             acc_val  \\\n",
      "0  [0.623921275138855, 0.6976807117462158, 0.7121...   \n",
      "1  [0.6406729817390442, 0.6908799409866333, 0.731...   \n",
      "2  [0.6285561919212341, 0.6425804495811462, 0.692...   \n",
      "3  [0.6412927508354187, 0.6877670884132385, 0.714...   \n",
      "4  [0.6606832146644592, 0.7027461528778076, 0.707...   \n",
      "\n",
      "                                    epoch_val_losses  train_f1  train_acc  \\\n",
      "0  [0.6786772012710571, 0.57835453748703, 0.56070...  0.842330   0.879080   \n",
      "1  [0.6920447945594788, 0.5986791849136353, 0.558...  0.853254   0.888063   \n",
      "2  [0.6920551657676697, 0.6386764645576477, 0.580...  0.836337   0.859167   \n",
      "3  [0.6799669861793518, 0.5961796045303345, 0.570...  0.851841   0.882875   \n",
      "4  [0.6376317739486694, 0.5761754512786865, 0.579...  0.848173   0.884605   \n",
      "\n",
      "    test_f1  test_acc  ...  train_precision  train_recall  test_precision  \\\n",
      "0  0.748598  0.800566  ...         0.867151      0.818890        0.767515   \n",
      "1  0.731460  0.802243  ...         0.895566      0.814759        0.769554   \n",
      "2  0.708900  0.751436  ...         0.779511      0.902099        0.650402   \n",
      "3  0.715156  0.768830  ...         0.851372      0.852310        0.711759   \n",
      "4  0.749606  0.808573  ...         0.886098      0.813360        0.783804   \n",
      "\n",
      "   test_recall                                       y_true_train  \\\n",
      "0     0.730591  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
      "1     0.696959  [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2     0.778962  [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3     0.718585  [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4     0.718267  [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                          y_true_val  \\\n",
      "0  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
      "\n",
      "                                    prediction_train  \\\n",
      "0  [[0.44406143], [0.038554665], [0.49479985], [0...   \n",
      "1  [[0.37658417], [0.12793112], [0.999977], [0.09...   \n",
      "2  [[0.17093161], [0.99999595], [0.34875742], [0....   \n",
      "3  [[0.4800571], [0.05595686], [0.9999261], [0.57...   \n",
      "4  [[0.34813276], [0.9999689], [0.0958265], [0.50...   \n",
      "\n",
      "                                     prediction_test  \\\n",
      "0  [[0.9998791], [0.999074], [0.24807827], [0.553...   \n",
      "1  [[0.042849418], [0.12709856], [0.046733346], [...   \n",
      "2  [[0.829288], [0.63625145], [0.53141963], [0.38...   \n",
      "3  [[0.25117657], [0.13082798], [0.24781206], [0....   \n",
      "4  [[0.08798116], [0.42510608], [0.5039877], [0.0...   \n",
      "\n",
      "                                         train_group  \\\n",
      "0  0        A06729\n",
      "1        A06047\n",
      "3        A0235...   \n",
      "1  0        A06729\n",
      "1        A06047\n",
      "2        A0132...   \n",
      "2  1        A06047\n",
      "2        A01326\n",
      "3        A0235...   \n",
      "3  0        A06729\n",
      "1        A06047\n",
      "2        A0132...   \n",
      "4  0        A06729\n",
      "2        A01326\n",
      "3        A0235...   \n",
      "\n",
      "                                          test_group  \n",
      "0  2        A01326\n",
      "6        A01326\n",
      "10       A0679...  \n",
      "1  7        A08357\n",
      "23       A08357\n",
      "51       A0835...  \n",
      "2  0        A06729\n",
      "4        A03493\n",
      "8        A0527...  \n",
      "3  3        A02351\n",
      "9        A01440\n",
      "11       A0144...  \n",
      "4  1        A06047\n",
      "5        A04068\n",
      "13       A0530...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "date and time = 26_09_2023__19_37_57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for params in product(*param_grid.values()):\n",
    "    detailed_results = []\n",
    "    param_dict = dict(zip(param_grid.keys(), params))\n",
    "    use_class_weights = param_dict['class_weights']\n",
    "    batch_size = param_dict['batch_size']\n",
    "    n_epochs = param_dict['epochs']\n",
    "    param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "    epoch_info = []\n",
    "    \n",
    "    #For each fold\n",
    "    for fold_idx, (train_indices, test_indices) in enumerate(sgkf.split(train_df_p['filename'], train_df_p['label'], groups=train_df_p['group'])):\n",
    "        \n",
    "        print(param_dict)\n",
    "        print (f'-----------------FOLD {fold_idx}-----------------')\n",
    "        \n",
    "        model = create_model_finetune(**param_dict_filtered)\n",
    "\n",
    "\n",
    "        train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p.iloc[train_indices],\n",
    "                                             directory=f\"./{main_folder}/train\",\n",
    "                                            target_size=(224, 224),\n",
    "                                             x_col = 'filename',\n",
    "                                             y_col = 'label',\n",
    "                                             class_mode = 'binary',\n",
    "                                             classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                             color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "        test_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p.iloc[test_indices],\n",
    "                                             directory=f\"./{main_folder}/train\",\n",
    "                                            target_size=(224, 224),\n",
    "                                             x_col = 'filename',\n",
    "                                             y_col = 'label',\n",
    "                                             class_mode = 'binary',\n",
    "                                             shuffle = False,\n",
    "                                             classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                             color_mode = 'rgb')\n",
    "        \n",
    "        train_group = train_df_p.iloc[train_indices]['group']\n",
    "        val_group = train_df_p.iloc[test_indices]['group']\n",
    "        #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "        \n",
    "        #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "        if use_class_weights:\n",
    "            y_train = train_gen.classes\n",
    "\n",
    "            class_weights = compute_class_weight('balanced',\n",
    "                                                     classes=np.unique(y_train),\n",
    "                                                     y=y_train)\n",
    "\n",
    "\n",
    "            class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "            #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "            #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "            history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,validation_data=test_gen,class_weight=class_weights)\n",
    "        else:\n",
    "            history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,validation_data=test_gen)\n",
    "                \n",
    "        train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "        \n",
    "        test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "        \n",
    "        #test_predictions = model.predict(test_gen)\n",
    "        \n",
    "        \n",
    "        print ( train_f1, train_acc, train_auc, train_precision,train_recall)\n",
    "        \n",
    "        print (test_f1, test_acc, test_auc, test_precision, test_recall)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print ('F1-macro:', test_score)\n",
    "         # Access loss, accuracy, and f1_macro values from history\n",
    "        epoch_losses = history.history['loss']\n",
    "        \n",
    "        epoch_accuracy = history.history['Accuracy']\n",
    "        epoch_val_accuracy = history.history['val_Accuracy']\n",
    "        #epoch_accuracies = score_callback.accuracies_train\n",
    "        #epoch_f1_macro = score_callback.train_f1_scores\n",
    "        epoch_val_losses = history.history['val_loss']\n",
    "        #epoch_val_accuracies = score_callback.accuracies_val\n",
    "        #epoch_val_f1_macro = score_callback.val_f1_scores\n",
    "        # After training\n",
    "        #print(\"F1-scores per epoch:\", score_callback.val_f1_scores)\n",
    "        #print(\"Accuracies per epoch:\", accuracy_callback.accuracies)\n",
    "        \n",
    "        epoch_info.append({\n",
    "            'params': param_dict,\n",
    "            'fold_number': fold_idx + 1,\n",
    "            'loss': epoch_losses,\n",
    "            #'val_loss':epoch_val_losses,\n",
    "            'acc_train': epoch_accuracy,\n",
    "            #'f1_train': epoch_f1_macro,\n",
    "            'acc_val': epoch_val_accuracy,\n",
    "            #'f1_val': epoch_val_f1_macro,\n",
    "            'epoch_val_losses':epoch_val_losses,\n",
    "            'train_f1': train_f1,\n",
    "            'train_acc': train_acc,\n",
    "            'test_f1': test_f1,\n",
    "            'test_acc': test_acc,\n",
    "            'train_auc':train_auc,\n",
    "            'test_auc':test_auc,\n",
    "            'train_precision':train_precision,\n",
    "            'train_recall':train_recall,\n",
    "            'test_precision':test_precision,\n",
    "            'test_recall':test_recall,\n",
    "            'y_true_train':y_true_train,\n",
    "            'y_true_val':y_true_val, #y_true_val\n",
    "            'prediction_train': prediction_train,\n",
    "            'prediction_test': prediction_test,\n",
    "            'train_group':train_group,\n",
    "            'test_group':val_group\n",
    "            \n",
    "        })\n",
    "    \n",
    "    detailed_results.extend(epoch_info)\n",
    "\n",
    "    # Convert detailed_results to a DataFrame\n",
    "    detailed_results_df = pd.DataFrame(detailed_results)\n",
    "\n",
    "    print(detailed_results_df)\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "    print(\"date and time =\", dt_string)\n",
    "\n",
    "\n",
    "    detailed_results_df.to_csv(main_folder+'_vgg.csv')\n",
    "    with open (main_folder+dt_string+'_vgg.pkl', 'wb') as f:\n",
    "        pickle.dump(detailed_results_df, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37345 validated image filenames belonging to 2 classes.\n",
      "Found 15957 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "1667/1667 [==============================] - 530s 316ms/step - loss: 1.1979 - Accuracy: 0.6288\n",
      "Epoch 2/30\n",
      "1667/1667 [==============================] - 547s 328ms/step - loss: 0.5977 - Accuracy: 0.6960\n",
      "Epoch 3/30\n",
      "1667/1667 [==============================] - 512s 307ms/step - loss: 0.5465 - Accuracy: 0.7317\n",
      "Epoch 4/30\n",
      "1667/1667 [==============================] - 555s 333ms/step - loss: 0.5186 - Accuracy: 0.7528\n",
      "Epoch 5/30\n",
      "1667/1667 [==============================] - 448s 269ms/step - loss: 0.4952 - Accuracy: 0.7710\n",
      "Epoch 6/30\n",
      "1667/1667 [==============================] - 428s 257ms/step - loss: 0.4814 - Accuracy: 0.7796\n",
      "Epoch 7/30\n",
      "1667/1667 [==============================] - 421s 253ms/step - loss: 0.4687 - Accuracy: 0.7880\n",
      "Epoch 8/30\n",
      "1667/1667 [==============================] - 424s 255ms/step - loss: 0.4544 - Accuracy: 0.7973\n",
      "Epoch 9/30\n",
      "1667/1667 [==============================] - 434s 260ms/step - loss: 0.4463 - Accuracy: 0.8010\n",
      "Epoch 10/30\n",
      "1667/1667 [==============================] - 441s 265ms/step - loss: 0.4361 - Accuracy: 0.8072\n",
      "Epoch 11/30\n",
      "1667/1667 [==============================] - 422s 253ms/step - loss: 0.4347 - Accuracy: 0.8090\n",
      "Epoch 12/30\n",
      "1667/1667 [==============================] - 433s 260ms/step - loss: 0.4219 - Accuracy: 0.8138\n",
      "Epoch 13/30\n",
      "1667/1667 [==============================] - 439s 263ms/step - loss: 0.4127 - Accuracy: 0.8218\n",
      "Epoch 14/30\n",
      "1667/1667 [==============================] - 421s 253ms/step - loss: 0.4130 - Accuracy: 0.8191\n",
      "Epoch 15/30\n",
      "1667/1667 [==============================] - 460s 276ms/step - loss: 0.4033 - Accuracy: 0.8262\n",
      "Epoch 16/30\n",
      "1667/1667 [==============================] - 427s 256ms/step - loss: 0.3931 - Accuracy: 0.8287\n",
      "Epoch 17/30\n",
      "1667/1667 [==============================] - 530s 318ms/step - loss: 0.3926 - Accuracy: 0.8304\n",
      "Epoch 18/30\n",
      "1667/1667 [==============================] - 497s 298ms/step - loss: 0.3893 - Accuracy: 0.8301\n",
      "Epoch 19/30\n",
      "1667/1667 [==============================] - 705s 423ms/step - loss: 0.3734 - Accuracy: 0.8414\n",
      "Epoch 20/30\n",
      "1667/1667 [==============================] - 547s 328ms/step - loss: 0.3736 - Accuracy: 0.8407\n",
      "Epoch 21/30\n",
      "1667/1667 [==============================] - 448s 269ms/step - loss: 0.3731 - Accuracy: 0.8392\n",
      "Epoch 22/30\n",
      "1667/1667 [==============================] - 557s 334ms/step - loss: 0.3571 - Accuracy: 0.8493\n",
      "Epoch 23/30\n",
      "1667/1667 [==============================] - 892s 535ms/step - loss: 0.3546 - Accuracy: 0.8491\n",
      "Epoch 24/30\n",
      "1667/1667 [==============================] - 491s 295ms/step - loss: 0.3532 - Accuracy: 0.8497\n",
      "Epoch 25/30\n",
      "1667/1667 [==============================] - 501s 301ms/step - loss: 0.3467 - Accuracy: 0.8538\n",
      "Epoch 26/30\n",
      "1667/1667 [==============================] - 565s 339ms/step - loss: 0.3339 - Accuracy: 0.8595\n",
      "Epoch 27/30\n",
      "1667/1667 [==============================] - 438s 263ms/step - loss: 0.3329 - Accuracy: 0.8603\n",
      "Epoch 28/30\n",
      "1667/1667 [==============================] - 470s 282ms/step - loss: 0.3324 - Accuracy: 0.8598\n",
      "Epoch 29/30\n",
      "1667/1667 [==============================] - 426s 255ms/step - loss: 0.3192 - Accuracy: 0.8656\n",
      "Epoch 30/30\n",
      "1667/1667 [==============================] - 425s 255ms/step - loss: 0.3141 - Accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "detailed_results=[]\n",
    "param_dict = {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': False}\n",
    "param_str = str(param_dict)\n",
    "batch_size = param_dict['batch_size']\n",
    "n_epochs = param_dict['epochs']\n",
    "use_class_weights = param_dict['class_weights']\n",
    "param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "test_info = []     \n",
    "model = create_model_finetune(**param_dict_filtered)\n",
    "\n",
    "\n",
    "train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p,\n",
    "                                     directory=f\"./{main_folder}/train\",\n",
    "                                    target_size=(224, 224),\n",
    "                                     x_col = 'filename',\n",
    "                                     y_col = 'label',\n",
    "                                     class_mode = 'binary',\n",
    "                                     classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                     color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "test_gen = train_datagen_p.flow_from_dataframe(dataframe=test_df_p,\n",
    "                                 directory=f\"./{main_folder}/test\",\n",
    "                                target_size=(224, 224),\n",
    "                                 x_col = 'filename',\n",
    "                                 y_col = 'label',\n",
    "                                 class_mode = 'binary',\n",
    "                                 shuffle = False,\n",
    "                                 classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                 color_mode = 'rgb')\n",
    "\n",
    "#train_group = train_df_p['group']\n",
    "#score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "\n",
    "class CombinedGen():\n",
    "    def __init__(self, *gens):\n",
    "        self.gens = gens\n",
    "\n",
    "    def generate(self):\n",
    "        while True:\n",
    "            for g in self.gens:\n",
    "                yield next(g)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(g) for g in self.gens])\n",
    "\n",
    "full_data_generator=CombinedGen(train_gen, test_gen)\n",
    "\n",
    "\n",
    "if use_class_weights:\n",
    "    y_train = train_gen.classes\n",
    "\n",
    "    class_weights = compute_class_weight('balanced',\n",
    "                                             classes=np.unique(y_train),\n",
    "                                             y=y_train)\n",
    "\n",
    "\n",
    "    class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "    #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "    #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "    history = model.fit(full_data_generator.generate(), batch_size = batch_size, epochs=n_epochs,class_weight=class_weights, steps_per_epoch=len(train_gen)+len(test_gen))\n",
    "else:\n",
    "    history = model.fit(full_data_generator.generate(), batch_size = batch_size, epochs=n_epochs, steps_per_epoch=len(train_gen)+len(test_gen))\n",
    "\n",
    "#train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "\n",
    "#test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "\n",
    "#test_predictions = model.predict(test_gen)\n",
    "\n",
    "\n",
    "#print ( train_f1, train_acc, train_auc, train_precision,train_recall)\n",
    "\n",
    "#print (test_f1, test_acc, test_auc, test_precision, test_recall)\n",
    "\n",
    "\n",
    "model.save(f'ecg_only_finetuned.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the training set, Testing on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37345 validated image filenames belonging to 2 classes.\n",
      "Found 15957 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "1168/1168 [==============================] - 456s 383ms/step - loss: 1.6674 - Accuracy: 0.6001 - val_loss: 0.6321 - val_Accuracy: 0.6766\n",
      "Epoch 2/30\n",
      "1168/1168 [==============================] - 422s 361ms/step - loss: 0.6599 - Accuracy: 0.6644 - val_loss: 0.5734 - val_Accuracy: 0.7071\n",
      "Epoch 3/30\n",
      "1168/1168 [==============================] - 416s 356ms/step - loss: 0.5791 - Accuracy: 0.7071 - val_loss: 0.5467 - val_Accuracy: 0.7318\n",
      "Epoch 4/30\n",
      "1168/1168 [==============================] - 396s 339ms/step - loss: 0.5459 - Accuracy: 0.7330 - val_loss: 0.5294 - val_Accuracy: 0.7474\n",
      "Epoch 5/30\n",
      "1168/1168 [==============================] - 444s 380ms/step - loss: 0.5169 - Accuracy: 0.7543 - val_loss: 0.5113 - val_Accuracy: 0.7617\n",
      "Epoch 6/30\n",
      "1168/1168 [==============================] - 386s 330ms/step - loss: 0.4999 - Accuracy: 0.7692 - val_loss: 0.5005 - val_Accuracy: 0.7713\n",
      "Epoch 7/30\n",
      "1168/1168 [==============================] - 391s 335ms/step - loss: 0.4812 - Accuracy: 0.7792 - val_loss: 0.5022 - val_Accuracy: 0.7713\n",
      "Epoch 8/30\n",
      "1168/1168 [==============================] - 399s 342ms/step - loss: 0.4687 - Accuracy: 0.7898 - val_loss: 0.4895 - val_Accuracy: 0.7796\n",
      "Epoch 9/30\n",
      "1168/1168 [==============================] - 380s 325ms/step - loss: 0.4580 - Accuracy: 0.7935 - val_loss: 0.4843 - val_Accuracy: 0.7830\n",
      "Epoch 10/30\n",
      "1168/1168 [==============================] - 380s 326ms/step - loss: 0.4516 - Accuracy: 0.7999 - val_loss: 0.4849 - val_Accuracy: 0.7832\n",
      "Epoch 11/30\n",
      "1168/1168 [==============================] - 384s 329ms/step - loss: 0.4407 - Accuracy: 0.8063 - val_loss: 0.4791 - val_Accuracy: 0.7913\n",
      "Epoch 12/30\n",
      "1168/1168 [==============================] - 389s 333ms/step - loss: 0.4359 - Accuracy: 0.8095 - val_loss: 0.4706 - val_Accuracy: 0.7930\n",
      "Epoch 13/30\n",
      "1168/1168 [==============================] - 380s 325ms/step - loss: 0.4281 - Accuracy: 0.8117 - val_loss: 0.4732 - val_Accuracy: 0.7904\n",
      "Epoch 14/30\n",
      "1168/1168 [==============================] - 387s 331ms/step - loss: 0.4214 - Accuracy: 0.8147 - val_loss: 0.4764 - val_Accuracy: 0.7920\n",
      "Epoch 15/30\n",
      "1168/1168 [==============================] - 382s 327ms/step - loss: 0.4147 - Accuracy: 0.8210 - val_loss: 0.4757 - val_Accuracy: 0.7956\n",
      "Epoch 16/30\n",
      "1168/1168 [==============================] - 405s 346ms/step - loss: 0.4075 - Accuracy: 0.8247 - val_loss: 0.4696 - val_Accuracy: 0.7967\n",
      "Epoch 17/30\n",
      "1168/1168 [==============================] - 379s 324ms/step - loss: 0.4025 - Accuracy: 0.8290 - val_loss: 0.4736 - val_Accuracy: 0.7979\n",
      "Epoch 18/30\n",
      "1168/1168 [==============================] - 392s 336ms/step - loss: 0.3939 - Accuracy: 0.8322 - val_loss: 0.4681 - val_Accuracy: 0.7978\n",
      "Epoch 19/30\n",
      "1168/1168 [==============================] - 392s 336ms/step - loss: 0.3887 - Accuracy: 0.8342 - val_loss: 0.4783 - val_Accuracy: 0.7919\n",
      "Epoch 20/30\n",
      "1168/1168 [==============================] - 385s 330ms/step - loss: 0.3837 - Accuracy: 0.8365 - val_loss: 0.4773 - val_Accuracy: 0.7978\n",
      "Epoch 21/30\n",
      "1168/1168 [==============================] - 376s 321ms/step - loss: 0.3778 - Accuracy: 0.8391 - val_loss: 0.4798 - val_Accuracy: 0.7914\n",
      "Epoch 22/30\n",
      "1168/1168 [==============================] - 378s 323ms/step - loss: 0.3716 - Accuracy: 0.8437 - val_loss: 0.4831 - val_Accuracy: 0.7953\n",
      "Epoch 23/30\n",
      "1168/1168 [==============================] - 388s 332ms/step - loss: 0.3693 - Accuracy: 0.8450 - val_loss: 0.4818 - val_Accuracy: 0.7985\n",
      "Epoch 24/30\n",
      "1168/1168 [==============================] - 378s 323ms/step - loss: 0.3602 - Accuracy: 0.8491 - val_loss: 0.4755 - val_Accuracy: 0.7975\n",
      "Epoch 25/30\n",
      "1168/1168 [==============================] - 377s 323ms/step - loss: 0.3541 - Accuracy: 0.8517 - val_loss: 0.4895 - val_Accuracy: 0.8013\n",
      "Epoch 26/30\n",
      "1168/1168 [==============================] - 382s 327ms/step - loss: 0.3497 - Accuracy: 0.8528 - val_loss: 0.4788 - val_Accuracy: 0.8014\n",
      "Epoch 27/30\n",
      "1168/1168 [==============================] - 386s 330ms/step - loss: 0.3442 - Accuracy: 0.8574 - val_loss: 0.4847 - val_Accuracy: 0.7976\n",
      "Epoch 28/30\n",
      "1168/1168 [==============================] - 375s 321ms/step - loss: 0.3400 - Accuracy: 0.8557 - val_loss: 0.4807 - val_Accuracy: 0.7985\n",
      "Epoch 29/30\n",
      "1168/1168 [==============================] - 397s 339ms/step - loss: 0.3318 - Accuracy: 0.8635 - val_loss: 0.5180 - val_Accuracy: 0.7851\n",
      "Epoch 30/30\n",
      "1168/1168 [==============================] - 388s 332ms/step - loss: 0.3286 - Accuracy: 0.8634 - val_loss: 0.4888 - val_Accuracy: 0.7979\n",
      "1168/1168 [==============================] - 208s 178ms/step\n",
      "499/499 [==============================] - 85s 171ms/step\n",
      "                                              params  fold_number  \\\n",
      "0  {'batch_size': 32, 'epochs': 30, 'optimizer': ...           -1   \n",
      "\n",
      "                                                loss  \\\n",
      "0  [1.6673976182937622, 0.6598511338233948, 0.579...   \n",
      "\n",
      "                                           acc_train  \\\n",
      "0  [0.6000803112983704, 0.6643727421760559, 0.707...   \n",
      "\n",
      "                                             acc_val  \\\n",
      "0  [0.676630973815918, 0.7070878148078918, 0.7317...   \n",
      "\n",
      "                                    epoch_val_losses  train_f1  train_acc  \\\n",
      "0  [0.632102906703949, 0.57340008020401, 0.546742...  0.822057   0.875485   \n",
      "\n",
      "    test_f1  test_acc  ...  train_precision  train_recall  test_precision  \\\n",
      "0  0.711099  0.797894  ...         0.949439      0.724813        0.827737   \n",
      "\n",
      "   test_recall                                       y_true_train  \\\n",
      "0     0.623273  [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                          y_true_val  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                    prediction_train  \\\n",
      "0  [[0.28202492], [0.033135094], [0.9984975], [0....   \n",
      "\n",
      "                                     prediction_test  \\\n",
      "0  [[0.12504016], [0.06786288], [0.38980484], [0....   \n",
      "\n",
      "                                         train_group  \\\n",
      "0  0        A06729\n",
      "2        A01326\n",
      "3        A0235...   \n",
      "\n",
      "                                          test_group  \n",
      "0  1        A06047\n",
      "5        A04068\n",
      "13       A0530...  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "date and time = 16_09_2023__19_15_51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "detailed_results=[]\n",
    "param_dict = {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 128, 'class_weights': False}\n",
    "param_str = str(param_dict)\n",
    "batch_size = param_dict['batch_size']\n",
    "n_epochs = param_dict['epochs']\n",
    "use_class_weights = param_dict['class_weights']\n",
    "param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "test_info = []     \n",
    "model = create_model_finetune(**param_dict_filtered)\n",
    "epoch_info = []\n",
    "\n",
    "train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p,\n",
    "                                     directory=f\"./{main_folder}/train\",\n",
    "                                    target_size=(224, 224),\n",
    "                                     x_col = 'filename',\n",
    "                                     y_col = 'label',\n",
    "                                     class_mode = 'binary',\n",
    "                                     classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                     color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "test_gen = train_datagen_p.flow_from_dataframe(dataframe=test_df_p,\n",
    "                                 directory=f\"./{main_folder}/test\",\n",
    "                                target_size=(224, 224),\n",
    "                                 x_col = 'filename',\n",
    "                                 y_col = 'label',\n",
    "                                 class_mode = 'binary',\n",
    "                                 shuffle = False,\n",
    "                                 classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                 color_mode = 'rgb')\n",
    "\n",
    "#train_group = train_df_p['group']\n",
    "#score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "\n",
    "\n",
    "if use_class_weights:\n",
    "    y_train = train_gen.classes\n",
    "\n",
    "    class_weights = compute_class_weight('balanced',\n",
    "                                             classes=np.unique(y_train),\n",
    "                                             y=y_train)\n",
    "\n",
    "\n",
    "    class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "    #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "    #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "    history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,class_weight=class_weights, validation_data= test_gen )\n",
    "else:\n",
    "    history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, validation_data= test_gen)\n",
    "\n",
    "train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "\n",
    "test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "\n",
    "  # Access loss, accuracy, and f1_macro values from history\n",
    "epoch_losses = history.history['loss']\n",
    "\n",
    "epoch_accuracy = history.history['Accuracy']\n",
    "epoch_val_accuracy = history.history['val_Accuracy']\n",
    "#epoch_accuracies = score_callback.accuracies_train\n",
    "#epoch_f1_macro = score_callback.train_f1_scores\n",
    "epoch_val_losses = history.history['val_loss']\n",
    "\n",
    "epoch_info.append({\n",
    "            'params': param_dict,\n",
    "            'fold_number': -1,\n",
    "            'loss': epoch_losses,\n",
    "            #'val_loss':epoch_val_losses,\n",
    "            'acc_train': epoch_accuracy,\n",
    "            #'f1_train': epoch_f1_macro,\n",
    "            'acc_val': epoch_val_accuracy,\n",
    "            #'f1_val': epoch_val_f1_macro,\n",
    "            'epoch_val_losses':epoch_val_losses,\n",
    "            'train_f1': train_f1,\n",
    "            'train_acc': train_acc,\n",
    "            'test_f1': test_f1,\n",
    "            'test_acc': test_acc,\n",
    "            'train_auc':train_auc,\n",
    "            'test_auc':test_auc,\n",
    "            'train_precision':train_precision,\n",
    "            'train_recall':train_recall,\n",
    "            'test_precision':test_precision,\n",
    "            'test_recall':test_recall,\n",
    "            'y_true_train':y_true_train,\n",
    "            'y_true_val':y_true_val, #y_true_val\n",
    "            'prediction_train': prediction_train,\n",
    "            'prediction_test': prediction_test,\n",
    "            'train_group':train_group,\n",
    "            'test_group':val_group\n",
    "            \n",
    "        })\n",
    "\n",
    "\n",
    "detailed_results.extend(epoch_info)\n",
    "\n",
    "# Convert detailed_results to a DataFrame\n",
    "detailed_results_df = pd.DataFrame(detailed_results)\n",
    "\n",
    "print(detailed_results_df)\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "\n",
    "detailed_results_df.to_csv(main_folder+'_vgg.csv')\n",
    "with open (main_folder+dt_string+'test_results_vgg.pkl', 'wb') as f:\n",
    "    pickle.dump(detailed_results_df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model creation function\n",
    "def create_model_single_mode(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    base_model.trainable = True\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    x = base_model.output\n",
    "    \n",
    "    \n",
    "    x = Flatten()(x)  # Add Global Average Pooling\n",
    "    x = Dense(neurons, activation='relu')(x)  # Add a fully connected layer\n",
    "    x = Dropout(dropout) (x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Replace softmax with sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "        \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['Accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_model_single_mode(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,926,209\n",
      "Trainable params: 17,926,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
