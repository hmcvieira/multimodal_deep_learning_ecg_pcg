{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG & PCG analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix as cm, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import itertools\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.utils import class_weight\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from itertools import product\n",
    "from keras.applications import VGG16\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = 'pcg_circor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCG Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p = pd.read_csv(f\"./{main_folder}/train/dataset.csv\",usecols=range(1,3))\n",
    "test_df_p = pd.read_csv(f\"./{main_folder}/test/dataset.csv\",usecols=range(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p['label']=train_df_p['label'].astype(str)\n",
    "test_df_p['label']=test_df_p['label'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_p['group'] = train_df_p['filename'].apply(lambda x: x.split('_')[0])\n",
    "test_df_p['group'] = test_df_p['filename'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_8.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_14.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_7.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_13.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>2199_8970.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>2200_8972.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>2200_8973.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>2199_8971.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>2200_8974.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8975 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename label group\n",
       "0           3_8.tiff     1     3\n",
       "1          5_14.tiff     1     5\n",
       "2           2_7.tiff     1     2\n",
       "3           1_3.tiff     1     1\n",
       "4          5_13.tiff     1     5\n",
       "...              ...   ...   ...\n",
       "8970  2199_8970.tiff     1  2199\n",
       "8971  2200_8972.tiff     1  2200\n",
       "8972  2200_8973.tiff     1  2200\n",
       "8973  2199_8971.tiff     1  2199\n",
       "8974  2200_8974.tiff     1  2200\n",
       "\n",
       "[8975 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_p = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_datagen_p = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen_p = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4878\n",
       "1    4097\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_p['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model creation function\n",
    "def create_model(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)  # Add Global Average Pooling\n",
    "    x = Dense(neurons, activation='relu')(x)  # Add a fully connected layer\n",
    "    x = Dropout(dropout) (x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Replace softmax with sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['Accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model creation function\n",
    "def create_model_finetune(optimizer='adam', learning_rate=0.001, dropout = 0.5, neurons = 128):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "        \n",
    "    base_model.trainable = True\n",
    "    num_layers = len(base_model.layers)\n",
    "    #num_layers_fine_tune = 8\n",
    "    num_layers_fine_tune = 18\n",
    "    for model_layer in base_model.layers[:num_layers - num_layers_fine_tune]:\n",
    "        model_layer.trainable = False\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    x = base_model.output\n",
    "    \n",
    "    \n",
    "    x = Flatten()(x)  # Add Global Average Pooling\n",
    "    x = Dense(neurons, activation='relu')(x)  # Add a fully connected layer\n",
    "    x = Dropout(dropout) (x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)  # Replace softmax with sigmoid for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "        \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['Accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model_finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,926,209\n",
      "Trainable params: 17,926,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, train_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.train_data = train_data\n",
    "        self.val_f1_scores = []\n",
    "        self.train_f1_scores = []\n",
    "        self.val_accuracies = []\n",
    "        self.train_accuracies = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_val, y_val = self.validation_data, self.validation_data.classes\n",
    "        X_train, y_train = self.train_data, self.train_data.classes\n",
    "\n",
    "        y_pred_val = self.model.predict(X_val)\n",
    "        y_pred_rounded_val = np.round(y_pred_val)  # Round predictions to binary values\n",
    "        y_pred_train = self.model.predict(X_train)\n",
    "        y_pred_rounded_train = np.round(y_pred_train)  # Round predictions to binary values\n",
    "        \n",
    "        macro_f1_val = f1_score(y_val, y_pred_rounded_val, average='macro')\n",
    "        self.val_f1_scores.append(macro_f1_val)\n",
    "        \n",
    "        macro_f1_train = f1_score(y_train, y_pred_rounded_train, average='macro')\n",
    "        self.train_f1_scores.append(macro_f1_train)\n",
    "        \n",
    "        acc_val = accuracy_score(y_val, y_pred_rounded_val)\n",
    "        self.val_accuracies.append(acc_val)\n",
    "        acc_train = accuracy_score(y_train, y_pred_rounded_train)\n",
    "        self.train_accuracies.append(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'batch_size': [ 32],\n",
    "    'epochs': [100],\n",
    "    'optimizer': ['adam'],\n",
    "    'learning_rate': [  0.000001],\n",
    "    'dropout':[ 0.5],\n",
    "    'neurons':[32],\n",
    "    'class_weights':[False]\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(generator, model):\n",
    "    y_true = generator.classes\n",
    "    predictions = model.predict(generator)\n",
    "    threshold = 0.5\n",
    "    predicted_classes = (predictions > threshold).astype(int)\n",
    "    \n",
    "    f1_value = f1_score(y_true,predicted_classes, average='binary' )\n",
    "    acc = accuracy_score(y_true, predicted_classes)\n",
    "    auc = roc_auc_score(y_true, predictions) \n",
    "    precision = precision_score(y_true, predicted_classes)\n",
    "    recall = recall_score(y_true, predicted_classes)\n",
    "    return f1_value, acc, auc, precision, recall, predictions, y_true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
      "-----------------FOLD 0-----------------\n",
      "Found 7179 validated image filenames belonging to 2 classes.\n",
      "Found 1796 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 114s 501ms/step - loss: 2.0451 - Accuracy: 0.5226 - val_loss: 0.8110 - val_Accuracy: 0.4978\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 117s 522ms/step - loss: 0.7930 - Accuracy: 0.5192 - val_loss: 0.7194 - val_Accuracy: 0.5089\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 117s 518ms/step - loss: 0.7198 - Accuracy: 0.5306 - val_loss: 0.6990 - val_Accuracy: 0.5379\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 116s 515ms/step - loss: 0.6993 - Accuracy: 0.5424 - val_loss: 0.6906 - val_Accuracy: 0.5551\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 116s 517ms/step - loss: 0.6936 - Accuracy: 0.5435 - val_loss: 0.6864 - val_Accuracy: 0.5629\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 121s 536ms/step - loss: 0.6813 - Accuracy: 0.5563 - val_loss: 0.6829 - val_Accuracy: 0.5774\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 120s 532ms/step - loss: 0.6755 - Accuracy: 0.5707 - val_loss: 0.6793 - val_Accuracy: 0.5791\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 120s 534ms/step - loss: 0.6711 - Accuracy: 0.5771 - val_loss: 0.6789 - val_Accuracy: 0.5857\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 118s 525ms/step - loss: 0.6621 - Accuracy: 0.5896 - val_loss: 0.6730 - val_Accuracy: 0.5891\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 120s 534ms/step - loss: 0.6554 - Accuracy: 0.6029 - val_loss: 0.6741 - val_Accuracy: 0.5980\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 128s 568ms/step - loss: 0.6500 - Accuracy: 0.5986 - val_loss: 0.6730 - val_Accuracy: 0.5902\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 119s 527ms/step - loss: 0.6468 - Accuracy: 0.6084 - val_loss: 0.6709 - val_Accuracy: 0.5941\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 137s 608ms/step - loss: 0.6419 - Accuracy: 0.6147 - val_loss: 0.6742 - val_Accuracy: 0.5885\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 132s 586ms/step - loss: 0.6346 - Accuracy: 0.6187 - val_loss: 0.6707 - val_Accuracy: 0.5963\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 121s 540ms/step - loss: 0.6292 - Accuracy: 0.6263 - val_loss: 0.6705 - val_Accuracy: 0.5997\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 118s 525ms/step - loss: 0.6295 - Accuracy: 0.6285 - val_loss: 0.6712 - val_Accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 118s 524ms/step - loss: 0.6214 - Accuracy: 0.6307 - val_loss: 0.6804 - val_Accuracy: 0.5846\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 117s 520ms/step - loss: 0.6201 - Accuracy: 0.6277 - val_loss: 0.6713 - val_Accuracy: 0.5908\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 119s 528ms/step - loss: 0.6116 - Accuracy: 0.6444 - val_loss: 0.6756 - val_Accuracy: 0.5930\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 117s 520ms/step - loss: 0.6065 - Accuracy: 0.6454 - val_loss: 0.6762 - val_Accuracy: 0.5958\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 118s 525ms/step - loss: 0.5993 - Accuracy: 0.6555 - val_loss: 0.6831 - val_Accuracy: 0.5935\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 119s 528ms/step - loss: 0.5957 - Accuracy: 0.6575 - val_loss: 0.7037 - val_Accuracy: 0.5857\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 118s 524ms/step - loss: 0.5903 - Accuracy: 0.6568 - val_loss: 0.6819 - val_Accuracy: 0.5796\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 117s 520ms/step - loss: 0.5883 - Accuracy: 0.6589 - val_loss: 0.6934 - val_Accuracy: 0.5746\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 118s 526ms/step - loss: 0.5796 - Accuracy: 0.6690 - val_loss: 0.6863 - val_Accuracy: 0.5902\n",
      "225/225 [==============================] - 39s 175ms/step\n",
      "57/57 [==============================] - 10s 168ms/step\n",
      "0.5652333700845278 0.6704276361610252 0.734512902520784 0.7136890951276103 0.4679038637055065\n",
      "0.47556528081692195 0.5996659242761693 0.5905015901635239 0.5811051693404634 0.4024691358024691\n",
      "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
      "-----------------FOLD 1-----------------\n",
      "Found 7170 validated image filenames belonging to 2 classes.\n",
      "Found 1805 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 117s 517ms/step - loss: 2.7946 - Accuracy: 0.5039 - val_loss: 0.9032 - val_Accuracy: 0.5147\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 122s 543ms/step - loss: 0.8516 - Accuracy: 0.5278 - val_loss: 0.7391 - val_Accuracy: 0.5274\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 117s 519ms/step - loss: 0.7426 - Accuracy: 0.5230 - val_loss: 0.7100 - val_Accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 119s 529ms/step - loss: 0.7061 - Accuracy: 0.5251 - val_loss: 0.7010 - val_Accuracy: 0.5407\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.6909 - Accuracy: 0.5367 - val_loss: 0.6971 - val_Accuracy: 0.5501\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 117s 519ms/step - loss: 0.6852 - Accuracy: 0.5431 - val_loss: 0.6926 - val_Accuracy: 0.5568\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 117s 518ms/step - loss: 0.6807 - Accuracy: 0.5379 - val_loss: 0.6912 - val_Accuracy: 0.5640\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 122s 543ms/step - loss: 0.6778 - Accuracy: 0.5312 - val_loss: 0.6884 - val_Accuracy: 0.5729\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 118s 524ms/step - loss: 0.6755 - Accuracy: 0.5762 - val_loss: 0.6882 - val_Accuracy: 0.5734\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 118s 524ms/step - loss: 0.6709 - Accuracy: 0.5819 - val_loss: 0.6846 - val_Accuracy: 0.5856\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6654 - Accuracy: 0.5879 - val_loss: 0.6861 - val_Accuracy: 0.5756\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 112s 499ms/step - loss: 0.6588 - Accuracy: 0.5927 - val_loss: 0.6832 - val_Accuracy: 0.5823\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 120s 534ms/step - loss: 0.6574 - Accuracy: 0.5993 - val_loss: 0.6804 - val_Accuracy: 0.5889\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 123s 547ms/step - loss: 0.6515 - Accuracy: 0.6013 - val_loss: 0.6811 - val_Accuracy: 0.5817\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 119s 529ms/step - loss: 0.6442 - Accuracy: 0.6057 - val_loss: 0.6820 - val_Accuracy: 0.5839\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 122s 541ms/step - loss: 0.6409 - Accuracy: 0.6103 - val_loss: 0.6796 - val_Accuracy: 0.5928\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 121s 536ms/step - loss: 0.6376 - Accuracy: 0.6138 - val_loss: 0.6808 - val_Accuracy: 0.5950\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 115s 511ms/step - loss: 0.6354 - Accuracy: 0.6187 - val_loss: 0.6780 - val_Accuracy: 0.5889\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 112s 497ms/step - loss: 0.6265 - Accuracy: 0.6160 - val_loss: 0.6813 - val_Accuracy: 0.5884\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.6252 - Accuracy: 0.6220 - val_loss: 0.6772 - val_Accuracy: 0.5884\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.6193 - Accuracy: 0.6251 - val_loss: 0.6809 - val_Accuracy: 0.5839\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.6059 - Accuracy: 0.6336 - val_loss: 0.6746 - val_Accuracy: 0.5961\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 112s 497ms/step - loss: 0.6069 - Accuracy: 0.6318 - val_loss: 0.6749 - val_Accuracy: 0.5978\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.6006 - Accuracy: 0.6428 - val_loss: 0.6777 - val_Accuracy: 0.5889\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 112s 498ms/step - loss: 0.5906 - Accuracy: 0.6445 - val_loss: 0.6882 - val_Accuracy: 0.5895\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 112s 497ms/step - loss: 0.5885 - Accuracy: 0.6441 - val_loss: 0.6832 - val_Accuracy: 0.6006\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.5881 - Accuracy: 0.6476 - val_loss: 0.6889 - val_Accuracy: 0.5967\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 112s 497ms/step - loss: 0.5780 - Accuracy: 0.6551 - val_loss: 0.6777 - val_Accuracy: 0.5956\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 112s 497ms/step - loss: 0.5730 - Accuracy: 0.6551 - val_loss: 0.6824 - val_Accuracy: 0.5889\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.5648 - Accuracy: 0.6594 - val_loss: 0.6928 - val_Accuracy: 0.5900\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.5687 - Accuracy: 0.6651 - val_loss: 0.6838 - val_Accuracy: 0.6011\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 112s 498ms/step - loss: 0.5579 - Accuracy: 0.6667 - val_loss: 0.6907 - val_Accuracy: 0.5928\n",
      "225/225 [==============================] - 38s 165ms/step\n",
      "57/57 [==============================] - 9s 165ms/step\n",
      "0.5344329896907216 0.6850767085076709 0.768279698115576 0.8150943396226416 0.39754601226993863\n",
      "0.4 0.5961218836565096 0.615500064180416 0.6428571428571429 0.2903225806451613\n",
      "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
      "-----------------FOLD 2-----------------\n",
      "Found 7226 validated image filenames belonging to 2 classes.\n",
      "Found 1749 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "226/226 [==============================] - 115s 500ms/step - loss: 2.2237 - Accuracy: 0.5155 - val_loss: 0.7769 - val_Accuracy: 0.5306\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 113s 499ms/step - loss: 0.7809 - Accuracy: 0.5345 - val_loss: 0.7011 - val_Accuracy: 0.5517\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 113s 499ms/step - loss: 0.7122 - Accuracy: 0.5479 - val_loss: 0.6879 - val_Accuracy: 0.5495\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 113s 499ms/step - loss: 0.6947 - Accuracy: 0.5555 - val_loss: 0.6846 - val_Accuracy: 0.5649\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.6871 - Accuracy: 0.5603 - val_loss: 0.6861 - val_Accuracy: 0.5626\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 113s 502ms/step - loss: 0.6832 - Accuracy: 0.5727 - val_loss: 0.6832 - val_Accuracy: 0.5672\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 124s 551ms/step - loss: 0.6795 - Accuracy: 0.5774 - val_loss: 0.6791 - val_Accuracy: 0.5723\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 119s 525ms/step - loss: 0.6773 - Accuracy: 0.5829 - val_loss: 0.6750 - val_Accuracy: 0.5923\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 115s 508ms/step - loss: 0.6729 - Accuracy: 0.5866 - val_loss: 0.6801 - val_Accuracy: 0.5786\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 120s 529ms/step - loss: 0.6678 - Accuracy: 0.5904 - val_loss: 0.6767 - val_Accuracy: 0.5860\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 120s 529ms/step - loss: 0.6653 - Accuracy: 0.5891 - val_loss: 0.6701 - val_Accuracy: 0.5941\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 114s 503ms/step - loss: 0.6633 - Accuracy: 0.5994 - val_loss: 0.6720 - val_Accuracy: 0.5878\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 116s 515ms/step - loss: 0.6583 - Accuracy: 0.6035 - val_loss: 0.6662 - val_Accuracy: 0.5901\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 125s 552ms/step - loss: 0.6549 - Accuracy: 0.6079 - val_loss: 0.6674 - val_Accuracy: 0.5872\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 127s 561ms/step - loss: 0.6504 - Accuracy: 0.6082 - val_loss: 0.6644 - val_Accuracy: 0.5935\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 118s 523ms/step - loss: 0.6466 - Accuracy: 0.6088 - val_loss: 0.6669 - val_Accuracy: 0.5855\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 118s 523ms/step - loss: 0.6465 - Accuracy: 0.6161 - val_loss: 0.6613 - val_Accuracy: 0.6043\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 116s 513ms/step - loss: 0.6420 - Accuracy: 0.6161 - val_loss: 0.6721 - val_Accuracy: 0.5906\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 122s 538ms/step - loss: 0.6410 - Accuracy: 0.6106 - val_loss: 0.6593 - val_Accuracy: 0.6032\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 121s 535ms/step - loss: 0.6303 - Accuracy: 0.6240 - val_loss: 0.6678 - val_Accuracy: 0.5941\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 122s 541ms/step - loss: 0.6282 - Accuracy: 0.6338 - val_loss: 0.6581 - val_Accuracy: 0.6038\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 121s 535ms/step - loss: 0.6192 - Accuracy: 0.6347 - val_loss: 0.6739 - val_Accuracy: 0.5935\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 117s 519ms/step - loss: 0.6225 - Accuracy: 0.6301 - val_loss: 0.6606 - val_Accuracy: 0.6049\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 117s 517ms/step - loss: 0.6171 - Accuracy: 0.6312 - val_loss: 0.6569 - val_Accuracy: 0.6038\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 117s 518ms/step - loss: 0.6112 - Accuracy: 0.6373 - val_loss: 0.6712 - val_Accuracy: 0.5963\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.6124 - Accuracy: 0.6439 - val_loss: 0.6623 - val_Accuracy: 0.6021\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.6087 - Accuracy: 0.6446 - val_loss: 0.6673 - val_Accuracy: 0.5981\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.6036 - Accuracy: 0.6484 - val_loss: 0.6560 - val_Accuracy: 0.5981\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5998 - Accuracy: 0.6499 - val_loss: 0.6617 - val_Accuracy: 0.6032\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5936 - Accuracy: 0.6518 - val_loss: 0.6759 - val_Accuracy: 0.6026\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5895 - Accuracy: 0.6618 - val_loss: 0.6780 - val_Accuracy: 0.5969\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5843 - Accuracy: 0.6644 - val_loss: 0.6805 - val_Accuracy: 0.5958\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5831 - Accuracy: 0.6654 - val_loss: 0.6631 - val_Accuracy: 0.6089\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 115s 508ms/step - loss: 0.5753 - Accuracy: 0.6663 - val_loss: 0.6709 - val_Accuracy: 0.6026\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5721 - Accuracy: 0.6710 - val_loss: 0.6755 - val_Accuracy: 0.6112\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5668 - Accuracy: 0.6745 - val_loss: 0.6767 - val_Accuracy: 0.5998\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5648 - Accuracy: 0.6728 - val_loss: 0.6597 - val_Accuracy: 0.6009\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.5591 - Accuracy: 0.6749 - val_loss: 0.6674 - val_Accuracy: 0.6083\n",
      "226/226 [==============================] - 38s 168ms/step\n",
      "55/55 [==============================] - 9s 168ms/step\n",
      "0.5779047619047618 0.6933296429559922 0.7749487479808639 0.7607823470411234 0.4659090909090909\n",
      "0.4741959611069559 0.5980560320182962 0.6220934800714484 0.6391129032258065 0.3769322235434007\n",
      "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
      "-----------------FOLD 3-----------------\n",
      "Found 7187 validated image filenames belonging to 2 classes.\n",
      "Found 1788 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 116s 512ms/step - loss: 2.1205 - Accuracy: 0.4963 - val_loss: 0.8243 - val_Accuracy: 0.5117\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 115s 510ms/step - loss: 0.8292 - Accuracy: 0.5250 - val_loss: 0.6945 - val_Accuracy: 0.5660\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 115s 509ms/step - loss: 0.7214 - Accuracy: 0.5422 - val_loss: 0.6811 - val_Accuracy: 0.5794\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6992 - Accuracy: 0.5603 - val_loss: 0.6782 - val_Accuracy: 0.5822\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6877 - Accuracy: 0.5620 - val_loss: 0.6743 - val_Accuracy: 0.5962\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 115s 509ms/step - loss: 0.6811 - Accuracy: 0.5684 - val_loss: 0.6726 - val_Accuracy: 0.5923\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 115s 511ms/step - loss: 0.6764 - Accuracy: 0.5794 - val_loss: 0.6700 - val_Accuracy: 0.5984\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6762 - Accuracy: 0.5760 - val_loss: 0.6692 - val_Accuracy: 0.6007\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6739 - Accuracy: 0.5794 - val_loss: 0.6662 - val_Accuracy: 0.6063\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6656 - Accuracy: 0.5829 - val_loss: 0.6656 - val_Accuracy: 0.6063\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6672 - Accuracy: 0.5879 - val_loss: 0.6631 - val_Accuracy: 0.6102\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 115s 510ms/step - loss: 0.6620 - Accuracy: 0.5939 - val_loss: 0.6599 - val_Accuracy: 0.6096\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 116s 516ms/step - loss: 0.6631 - Accuracy: 0.5927 - val_loss: 0.6613 - val_Accuracy: 0.6135\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 117s 522ms/step - loss: 0.6583 - Accuracy: 0.5894 - val_loss: 0.6593 - val_Accuracy: 0.6158\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 122s 541ms/step - loss: 0.6539 - Accuracy: 0.6019 - val_loss: 0.6656 - val_Accuracy: 0.6051\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 125s 554ms/step - loss: 0.6473 - Accuracy: 0.6064 - val_loss: 0.6575 - val_Accuracy: 0.6169\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 117s 520ms/step - loss: 0.6523 - Accuracy: 0.6062 - val_loss: 0.6531 - val_Accuracy: 0.6214\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 118s 526ms/step - loss: 0.6474 - Accuracy: 0.6114 - val_loss: 0.6544 - val_Accuracy: 0.6174\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 124s 551ms/step - loss: 0.6431 - Accuracy: 0.6124 - val_loss: 0.6522 - val_Accuracy: 0.6163\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 117s 521ms/step - loss: 0.6436 - Accuracy: 0.6117 - val_loss: 0.6492 - val_Accuracy: 0.6169\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 121s 537ms/step - loss: 0.6332 - Accuracy: 0.6210 - val_loss: 0.6516 - val_Accuracy: 0.6191\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 118s 526ms/step - loss: 0.6354 - Accuracy: 0.6171 - val_loss: 0.6478 - val_Accuracy: 0.6152\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 130s 578ms/step - loss: 0.6306 - Accuracy: 0.6217 - val_loss: 0.6502 - val_Accuracy: 0.6180\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 121s 539ms/step - loss: 0.6240 - Accuracy: 0.6317 - val_loss: 0.6542 - val_Accuracy: 0.6096\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 125s 556ms/step - loss: 0.6231 - Accuracy: 0.6254 - val_loss: 0.6476 - val_Accuracy: 0.6253\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 123s 545ms/step - loss: 0.6225 - Accuracy: 0.6361 - val_loss: 0.6527 - val_Accuracy: 0.6141\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 120s 535ms/step - loss: 0.6198 - Accuracy: 0.6297 - val_loss: 0.6532 - val_Accuracy: 0.6147\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 119s 527ms/step - loss: 0.6127 - Accuracy: 0.6430 - val_loss: 0.6523 - val_Accuracy: 0.6057\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.6081 - Accuracy: 0.6378 - val_loss: 0.6462 - val_Accuracy: 0.6292\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 115s 511ms/step - loss: 0.6080 - Accuracy: 0.6438 - val_loss: 0.6470 - val_Accuracy: 0.6152\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.5971 - Accuracy: 0.6530 - val_loss: 0.6503 - val_Accuracy: 0.6174\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 115s 511ms/step - loss: 0.5981 - Accuracy: 0.6494 - val_loss: 0.6548 - val_Accuracy: 0.5984\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 118s 523ms/step - loss: 0.5912 - Accuracy: 0.6499 - val_loss: 0.6486 - val_Accuracy: 0.6275\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 120s 533ms/step - loss: 0.5880 - Accuracy: 0.6604 - val_loss: 0.6566 - val_Accuracy: 0.6152\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 120s 534ms/step - loss: 0.5881 - Accuracy: 0.6615 - val_loss: 0.6524 - val_Accuracy: 0.6063\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 123s 547ms/step - loss: 0.5800 - Accuracy: 0.6633 - val_loss: 0.6502 - val_Accuracy: 0.6247\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 122s 540ms/step - loss: 0.5783 - Accuracy: 0.6686 - val_loss: 0.6507 - val_Accuracy: 0.6214\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 121s 537ms/step - loss: 0.5720 - Accuracy: 0.6711 - val_loss: 0.6541 - val_Accuracy: 0.6320\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 118s 526ms/step - loss: 0.5716 - Accuracy: 0.6697 - val_loss: 0.6519 - val_Accuracy: 0.6208\n",
      "225/225 [==============================] - 41s 182ms/step\n",
      "56/56 [==============================] - 9s 170ms/step\n",
      "0.5524193548387096 0.6911089467093363 0.7594658538847592 0.8277945619335347 0.4145234493192133\n",
      "0.46228710462287104 0.6291946308724832 0.6248263255040364 0.6462585034013606 0.35984848484848486\n",
      "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
      "-----------------FOLD 4-----------------\n",
      "Found 7138 validated image filenames belonging to 2 classes.\n",
      "Found 1837 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "224/224 [==============================] - 119s 527ms/step - loss: 3.2690 - Accuracy: 0.5126 - val_loss: 0.9380 - val_Accuracy: 0.5373\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 115s 511ms/step - loss: 1.0620 - Accuracy: 0.5238 - val_loss: 0.7420 - val_Accuracy: 0.5721\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 114s 510ms/step - loss: 0.7961 - Accuracy: 0.5493 - val_loss: 0.7010 - val_Accuracy: 0.5569\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.7253 - Accuracy: 0.5560 - val_loss: 0.6844 - val_Accuracy: 0.5716\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.7052 - Accuracy: 0.5521 - val_loss: 0.6799 - val_Accuracy: 0.5749\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.6967 - Accuracy: 0.5709 - val_loss: 0.6779 - val_Accuracy: 0.5803\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.6864 - Accuracy: 0.5636 - val_loss: 0.6756 - val_Accuracy: 0.5830\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.6837 - Accuracy: 0.5657 - val_loss: 0.6754 - val_Accuracy: 0.5868\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.6759 - Accuracy: 0.5712 - val_loss: 0.6717 - val_Accuracy: 0.5906\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 114s 510ms/step - loss: 0.6721 - Accuracy: 0.5794 - val_loss: 0.6712 - val_Accuracy: 0.5939\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 115s 512ms/step - loss: 0.6651 - Accuracy: 0.5876 - val_loss: 0.6681 - val_Accuracy: 0.5972\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 114s 511ms/step - loss: 0.6610 - Accuracy: 0.5877 - val_loss: 0.6669 - val_Accuracy: 0.5972\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 114s 510ms/step - loss: 0.6567 - Accuracy: 0.5916 - val_loss: 0.6693 - val_Accuracy: 0.5928\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 114s 510ms/step - loss: 0.6522 - Accuracy: 0.6010 - val_loss: 0.6667 - val_Accuracy: 0.5977\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 123s 549ms/step - loss: 0.6502 - Accuracy: 0.6003 - val_loss: 0.6676 - val_Accuracy: 0.5901\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 119s 531ms/step - loss: 0.6414 - Accuracy: 0.6126 - val_loss: 0.6635 - val_Accuracy: 0.6032\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 122s 543ms/step - loss: 0.6405 - Accuracy: 0.6185 - val_loss: 0.6648 - val_Accuracy: 0.6010\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 116s 518ms/step - loss: 0.6361 - Accuracy: 0.6209 - val_loss: 0.6657 - val_Accuracy: 0.5961\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 116s 519ms/step - loss: 0.6260 - Accuracy: 0.6328 - val_loss: 0.6633 - val_Accuracy: 0.5983\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 119s 533ms/step - loss: 0.6260 - Accuracy: 0.6273 - val_loss: 0.6601 - val_Accuracy: 0.6010\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.6219 - Accuracy: 0.6332 - val_loss: 0.6586 - val_Accuracy: 0.6097\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.6159 - Accuracy: 0.6379 - val_loss: 0.6603 - val_Accuracy: 0.6064\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.6119 - Accuracy: 0.6463 - val_loss: 0.6610 - val_Accuracy: 0.6004\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.6066 - Accuracy: 0.6429 - val_loss: 0.6623 - val_Accuracy: 0.6091\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.6002 - Accuracy: 0.6524 - val_loss: 0.6682 - val_Accuracy: 0.5972\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5997 - Accuracy: 0.6561 - val_loss: 0.6645 - val_Accuracy: 0.5966\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5944 - Accuracy: 0.6547 - val_loss: 0.6725 - val_Accuracy: 0.5912\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5856 - Accuracy: 0.6618 - val_loss: 0.6872 - val_Accuracy: 0.5874\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5818 - Accuracy: 0.6656 - val_loss: 0.6685 - val_Accuracy: 0.6042\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5802 - Accuracy: 0.6634 - val_loss: 0.6677 - val_Accuracy: 0.6042\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 114s 509ms/step - loss: 0.5729 - Accuracy: 0.6804 - val_loss: 0.6665 - val_Accuracy: 0.6097\n",
      "224/224 [==============================] - 38s 168ms/step\n",
      "58/58 [==============================] - 10s 168ms/step\n",
      "0.5815028901734104 0.6957130848977304 0.7685640149072563 0.7900523560209424 0.4600609756097561\n",
      "0.46049661399548536 0.6096897114861187 0.6099611203110376 0.59765625 0.37454100367197063\n",
      "                                              params  fold_number  \\\n",
      "0  {'batch_size': 32, 'epochs': 100, 'optimizer':...            1   \n",
      "1  {'batch_size': 32, 'epochs': 100, 'optimizer':...            2   \n",
      "2  {'batch_size': 32, 'epochs': 100, 'optimizer':...            3   \n",
      "3  {'batch_size': 32, 'epochs': 100, 'optimizer':...            4   \n",
      "4  {'batch_size': 32, 'epochs': 100, 'optimizer':...            5   \n",
      "\n",
      "                                                loss  \\\n",
      "0  [2.0451323986053467, 0.7930183410644531, 0.719...   \n",
      "1  [2.7945797443389893, 0.8515953421592712, 0.742...   \n",
      "2  [2.2237308025360107, 0.780946671962738, 0.7121...   \n",
      "3  [2.120481252670288, 0.8292458057403564, 0.7213...   \n",
      "4  [3.2690370082855225, 1.0620434284210205, 0.796...   \n",
      "\n",
      "                                           acc_train  \\\n",
      "0  [0.5226354598999023, 0.5191530585289001, 0.530...   \n",
      "1  [0.503905177116394, 0.527754545211792, 0.52301...   \n",
      "2  [0.5154995918273926, 0.5344588756561279, 0.547...   \n",
      "3  [0.49631279706954956, 0.5249756574630737, 0.54...   \n",
      "4  [0.5126085877418518, 0.5238161683082581, 0.549...   \n",
      "\n",
      "                                             acc_val  \\\n",
      "0  [0.49777284264564514, 0.5089086890220642, 0.53...   \n",
      "1  [0.5146814584732056, 0.5274237990379333, 0.535...   \n",
      "2  [0.5305889248847961, 0.5517438650131226, 0.549...   \n",
      "3  [0.5117449760437012, 0.5659955143928528, 0.579...   \n",
      "4  [0.5372890830039978, 0.5721284747123718, 0.556...   \n",
      "\n",
      "                                    epoch_val_losses  train_f1  train_acc  \\\n",
      "0  [0.8110294342041016, 0.719371497631073, 0.6989...  0.565233   0.670428   \n",
      "1  [0.9032118916511536, 0.7390905022621155, 0.709...  0.534433   0.685077   \n",
      "2  [0.7768779397010803, 0.7010623812675476, 0.687...  0.577905   0.693330   \n",
      "3  [0.8243473172187805, 0.6945291757583618, 0.681...  0.552419   0.691109   \n",
      "4  [0.9379795789718628, 0.7419531941413879, 0.701...  0.581503   0.695713   \n",
      "\n",
      "    test_f1  test_acc  ...  train_precision  train_recall  test_precision  \\\n",
      "0  0.475565  0.599666  ...         0.713689      0.467904        0.581105   \n",
      "1  0.400000  0.596122  ...         0.815094      0.397546        0.642857   \n",
      "2  0.474196  0.598056  ...         0.760782      0.465909        0.639113   \n",
      "3  0.462287  0.629195  ...         0.827795      0.414523        0.646259   \n",
      "4  0.460497  0.609690  ...         0.790052      0.460061        0.597656   \n",
      "\n",
      "   test_recall                                       y_true_train  \\\n",
      "0     0.402469  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "1     0.290323  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "2     0.376932  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "3     0.359848  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "4     0.374541  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                          y_true_val  \\\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                    prediction_train  \\\n",
      "0  [[0.32283753], [0.62244993], [0.7961711], [0.4...   \n",
      "1  [[0.43044913], [0.458285], [0.47712737], [0.45...   \n",
      "2  [[0.32799363], [0.74393684], [0.4738838], [0.4...   \n",
      "3  [[0.45865905], [0.69100326], [0.5209665], [0.4...   \n",
      "4  [[0.4845625], [0.6731599], [0.54961896], [0.66...   \n",
      "\n",
      "                                     prediction_test  \\\n",
      "0  [[0.4720452], [0.4622323], [0.41084522], [0.43...   \n",
      "1  [[0.72579676], [0.81081855], [0.46271637], [0....   \n",
      "2  [[0.32974902], [0.691469], [0.55718935], [0.71...   \n",
      "3  [[0.27610168], [0.43360063], [0.43224], [0.438...   \n",
      "4  [[0.31430995], [0.40711147], [0.45852396], [0....   \n",
      "\n",
      "                                         train_group  \\\n",
      "0  0          3\n",
      "1          5\n",
      "2          2\n",
      "3      ...   \n",
      "1  0          3\n",
      "2          2\n",
      "3          1\n",
      "5      ...   \n",
      "2  0          3\n",
      "1          5\n",
      "3          1\n",
      "4      ...   \n",
      "3  0          3\n",
      "1          5\n",
      "2          2\n",
      "3      ...   \n",
      "4  1          5\n",
      "2          2\n",
      "4          5\n",
      "9      ...   \n",
      "\n",
      "                                          test_group  \n",
      "0  15         0\n",
      "16         0\n",
      "35        10\n",
      "36     ...  \n",
      "1  1          5\n",
      "4          5\n",
      "17         5\n",
      "20     ...  \n",
      "2  2          2\n",
      "9          4\n",
      "10         4\n",
      "22     ...  \n",
      "3  45        12\n",
      "46        12\n",
      "51        14\n",
      "53     ...  \n",
      "4  0          3\n",
      "3          1\n",
      "5          1\n",
      "6      ...  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "date and time = 03_10_2023__16_04_42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for params in product(*param_grid.values()):\n",
    "    detailed_results = []\n",
    "    param_dict = dict(zip(param_grid.keys(), params))\n",
    "    \n",
    "    batch_size = param_dict['batch_size']\n",
    "    n_epochs = param_dict['epochs']\n",
    "    use_class_weights = param_dict['class_weights']\n",
    "    param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "    epoch_info = []\n",
    "    \n",
    "    #For each fold\n",
    "    for fold_idx, (train_indices, test_indices) in enumerate(sgkf.split(train_df_p['filename'], train_df_p['label'], groups=train_df_p['group'])):\n",
    "        \n",
    "        print(param_dict)\n",
    "        print (f'-----------------FOLD {fold_idx}-----------------')\n",
    "        \n",
    "        model = create_model_finetune(**param_dict_filtered)\n",
    "\n",
    "\n",
    "        train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p.iloc[train_indices],\n",
    "                                             directory=f\"./{main_folder}/train\",\n",
    "                                            target_size=(224, 224),\n",
    "                                             x_col = 'filename',\n",
    "                                             y_col = 'label',\n",
    "                                             class_mode = 'binary',\n",
    "                                             classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                             color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "        test_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p.iloc[test_indices],\n",
    "                                             directory=f\"./{main_folder}/train\",\n",
    "                                            target_size=(224, 224),\n",
    "                                             x_col = 'filename',\n",
    "                                             y_col = 'label',\n",
    "                                             class_mode = 'binary',\n",
    "                                             shuffle = False,\n",
    "                                             classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                             color_mode = 'rgb')\n",
    "        \n",
    "        train_group = train_df_p.iloc[train_indices]['group']\n",
    "        val_group = train_df_p.iloc[test_indices]['group']\n",
    "        \n",
    "        if use_class_weights:\n",
    "            y_train = train_gen.classes\n",
    "\n",
    "            class_weights = compute_class_weight('balanced',\n",
    "                                                     classes=np.unique(y_train),\n",
    "                                                     y=y_train)\n",
    "            \n",
    "            \n",
    "            class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "            #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "            #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "            history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,validation_data=test_gen,class_weight=class_weights, callback=[early_stopping])\n",
    "        else:\n",
    "            history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,validation_data=test_gen, callbacks=[early_stopping])\n",
    "        \n",
    "        \n",
    "        train_gen.reset()\n",
    "        test_gen.reset()\n",
    "        train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "        \n",
    "        test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "        \n",
    "        #test_predictions = model.predict(test_gen)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print ( train_f1, train_acc, train_auc, train_precision,train_recall)\n",
    "        \n",
    "        print (test_f1, test_acc, test_auc, test_precision, test_recall)\n",
    "        \n",
    "        \n",
    "        \n",
    "        epoch_losses = history.history['loss']\n",
    "        \n",
    "        epoch_accuracy = history.history['Accuracy']\n",
    "        epoch_val_accuracy = history.history['val_Accuracy']\n",
    "        #epoch_accuracies = score_callback.accuracies_train\n",
    "        #epoch_f1_macro = score_callback.train_f1_scores\n",
    "        epoch_val_losses = history.history['val_loss']\n",
    "        #epoch_val_accuracies = score_callback.accuracies_val\n",
    "        #epoch_val_f1_macro = score_callback.val_f1_scores\n",
    "        # After training\n",
    "        #print(\"F1-scores per epoch:\", score_callback.val_f1_scores)\n",
    "        #print(\"Accuracies per epoch:\", accuracy_callback.accuracies)\n",
    "        \n",
    "        epoch_info.append({\n",
    "            'params': param_dict,\n",
    "            'fold_number': fold_idx + 1,\n",
    "            'loss': epoch_losses,\n",
    "            #'val_loss':epoch_val_losses,\n",
    "            'acc_train': epoch_accuracy,\n",
    "            #'f1_train': epoch_f1_macro,\n",
    "            'acc_val': epoch_val_accuracy,\n",
    "            #'f1_val': epoch_val_f1_macro,\n",
    "            'epoch_val_losses':epoch_val_losses,\n",
    "            'train_f1': train_f1,\n",
    "            'train_acc': train_acc,\n",
    "            'test_f1': test_f1,\n",
    "            'test_acc': test_acc,\n",
    "            'train_auc':train_auc,\n",
    "            'test_auc':test_auc,\n",
    "            'train_precision':train_precision,\n",
    "            'train_recall':train_recall,\n",
    "            'test_precision':test_precision,\n",
    "            'test_recall':test_recall,\n",
    "            'y_true_train':y_true_train,\n",
    "            'y_true_val':y_true_val, #y_true_val\n",
    "            'prediction_train': prediction_train,\n",
    "            'prediction_test': prediction_test,\n",
    "            'train_group':train_group,\n",
    "            'test_group':val_group\n",
    "            \n",
    "        })\n",
    "    \n",
    "    detailed_results.extend(epoch_info)\n",
    "\n",
    "    # Convert detailed_results to a DataFrame\n",
    "    detailed_results_df = pd.DataFrame(detailed_results)\n",
    "\n",
    "    print(detailed_results_df)\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "    print(\"date and time =\", dt_string)\n",
    "\n",
    "\n",
    "    detailed_results_df.to_csv(main_folder+'_vgg.csv')\n",
    "    with open (main_folder+dt_string+'cvcircor_vgg.pkl', 'wb') as f:\n",
    "        pickle.dump(detailed_results_df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'.\\physionet2016_bcdef01_09_2023__13_23_13_vgg.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Selected model on full training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8975 validated image filenames belonging to 2 classes.\n",
      "Found 3970 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "281/281 [==============================] - 173s 612ms/step - loss: 1.7370 - Accuracy: 0.5180 - val_loss: 0.7870 - val_Accuracy: 0.5025\n",
      "Epoch 2/20\n",
      "281/281 [==============================] - 155s 550ms/step - loss: 0.7967 - Accuracy: 0.5199 - val_loss: 0.7288 - val_Accuracy: 0.4834\n",
      "Epoch 3/20\n",
      "281/281 [==============================] - 176s 628ms/step - loss: 0.7214 - Accuracy: 0.5460 - val_loss: 0.7083 - val_Accuracy: 0.4806\n",
      "Epoch 4/20\n",
      "281/281 [==============================] - 173s 615ms/step - loss: 0.6970 - Accuracy: 0.5625 - val_loss: 0.7074 - val_Accuracy: 0.4710\n",
      "Epoch 5/20\n",
      "281/281 [==============================] - 169s 603ms/step - loss: 0.6892 - Accuracy: 0.5611 - val_loss: 0.7028 - val_Accuracy: 0.4791\n",
      "Epoch 6/20\n",
      "281/281 [==============================] - 151s 537ms/step - loss: 0.6827 - Accuracy: 0.5662 - val_loss: 0.7021 - val_Accuracy: 0.4834\n",
      "Epoch 7/20\n",
      "281/281 [==============================] - 154s 549ms/step - loss: 0.6811 - Accuracy: 0.5664 - val_loss: 0.7009 - val_Accuracy: 0.4912\n",
      "Epoch 8/20\n",
      "281/281 [==============================] - 157s 558ms/step - loss: 0.6762 - Accuracy: 0.5740 - val_loss: 0.7073 - val_Accuracy: 0.4796\n",
      "Epoch 9/20\n",
      "281/281 [==============================] - 157s 560ms/step - loss: 0.6718 - Accuracy: 0.5824 - val_loss: 0.7025 - val_Accuracy: 0.4874\n",
      "Epoch 10/20\n",
      "281/281 [==============================] - 152s 541ms/step - loss: 0.6693 - Accuracy: 0.5867 - val_loss: 0.6986 - val_Accuracy: 0.5018\n",
      "Epoch 11/20\n",
      "281/281 [==============================] - 156s 556ms/step - loss: 0.6650 - Accuracy: 0.5892 - val_loss: 0.7041 - val_Accuracy: 0.4990\n",
      "Epoch 12/20\n",
      "281/281 [==============================] - 155s 553ms/step - loss: 0.6626 - Accuracy: 0.5915 - val_loss: 0.7064 - val_Accuracy: 0.4892\n",
      "Epoch 13/20\n",
      "281/281 [==============================] - 154s 549ms/step - loss: 0.6618 - Accuracy: 0.5949 - val_loss: 0.6991 - val_Accuracy: 0.5055\n",
      "Epoch 14/20\n",
      "281/281 [==============================] - 158s 563ms/step - loss: 0.6529 - Accuracy: 0.5989 - val_loss: 0.7014 - val_Accuracy: 0.5164\n",
      "Epoch 15/20\n",
      "281/281 [==============================] - 153s 543ms/step - loss: 0.6516 - Accuracy: 0.6077 - val_loss: 0.7151 - val_Accuracy: 0.4947\n",
      "Epoch 16/20\n",
      "281/281 [==============================] - 161s 572ms/step - loss: 0.6467 - Accuracy: 0.6060 - val_loss: 0.7047 - val_Accuracy: 0.4982\n",
      "Epoch 17/20\n",
      "281/281 [==============================] - 154s 547ms/step - loss: 0.6434 - Accuracy: 0.6129 - val_loss: 0.7012 - val_Accuracy: 0.5028\n",
      "Epoch 18/20\n",
      "281/281 [==============================] - 158s 561ms/step - loss: 0.6330 - Accuracy: 0.6156 - val_loss: 0.7152 - val_Accuracy: 0.5272\n",
      "Epoch 19/20\n",
      "281/281 [==============================] - 167s 596ms/step - loss: 0.6337 - Accuracy: 0.6164 - val_loss: 0.7161 - val_Accuracy: 0.5083\n",
      "Epoch 20/20\n",
      "281/281 [==============================] - 185s 658ms/step - loss: 0.6315 - Accuracy: 0.6223 - val_loss: 0.7100 - val_Accuracy: 0.5169\n",
      "281/281 [==============================] - 52s 185ms/step\n",
      "125/125 [==============================] - 23s 184ms/step\n",
      "                                              params  fold_number  \\\n",
      "0  {'batch_size': 32, 'epochs': 20, 'optimizer': ...           -1   \n",
      "\n",
      "                                                loss  \\\n",
      "0  [3.2690370082855225, 1.0620434284210205, 0.796...   \n",
      "\n",
      "                                           acc_train  \\\n",
      "0  [0.5126085877418518, 0.5238161683082581, 0.549...   \n",
      "\n",
      "                                             acc_val  \\\n",
      "0  [0.5372890830039978, 0.5721284747123718, 0.556...   \n",
      "\n",
      "                                    epoch_val_losses  train_f1  train_acc  \\\n",
      "0  [0.9379795789718628, 0.7419531941413879, 0.701...  0.533147   0.664958   \n",
      "\n",
      "    test_f1  test_acc  ...  train_precision  train_recall  test_precision  \\\n",
      "0  0.406559  0.516877  ...         0.732509      0.419087         0.62931   \n",
      "\n",
      "   test_recall                                       y_true_train  \\\n",
      "0     0.300274  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                          y_true_val  \\\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
      "\n",
      "                                    prediction_train  \\\n",
      "0  [[0.38985756], [0.86267084], [0.7463435], [0.3...   \n",
      "\n",
      "                                     prediction_test  \\\n",
      "0  [[0.4862829], [0.5056194], [0.741575], [0.4223...   \n",
      "\n",
      "                                         train_group  \\\n",
      "0  1          5\n",
      "2          2\n",
      "4          5\n",
      "9      ...   \n",
      "\n",
      "                                          test_group  \n",
      "0  0          3\n",
      "3          1\n",
      "5          1\n",
      "6      ...  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "date and time = 03_10_2023__19_17_22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "detailed_results=[]\n",
    "param_dict = {'batch_size': 32, 'epochs': 20, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
    "param_str = str(param_dict)\n",
    "batch_size = param_dict['batch_size']\n",
    "n_epochs = param_dict['epochs']\n",
    "use_class_weights = param_dict['class_weights']\n",
    "param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "test_info = []     \n",
    "model = create_model_finetune(**param_dict_filtered)\n",
    "epoch_info = []\n",
    "\n",
    "train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p,\n",
    "                                     directory=f\"./{main_folder}/train\",\n",
    "                                    target_size=(224, 224),\n",
    "                                     x_col = 'filename',\n",
    "                                     y_col = 'label',\n",
    "                                     class_mode = 'binary',\n",
    "                                     classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                     color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "test_gen = train_datagen_p.flow_from_dataframe(dataframe=test_df_p,\n",
    "                                 directory=f\"./{main_folder}/test\",\n",
    "                                target_size=(224, 224),\n",
    "                                 x_col = 'filename',\n",
    "                                 y_col = 'label',\n",
    "                                 class_mode = 'binary',\n",
    "                                 shuffle = False,\n",
    "                                 classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                 color_mode = 'rgb')\n",
    "\n",
    "#train_group = train_df_p['group']\n",
    "#score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "\n",
    "\n",
    "if use_class_weights:\n",
    "    y_train = train_gen.classes\n",
    "\n",
    "    class_weights = compute_class_weight('balanced',\n",
    "                                             classes=np.unique(y_train),\n",
    "                                             y=y_train)\n",
    "\n",
    "\n",
    "    class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "    #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "    #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "    history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs,class_weight=class_weights, validation_data= test_gen )\n",
    "else:\n",
    "    history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, validation_data= test_gen)\n",
    "\n",
    "train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "\n",
    "test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "\n",
    "\n",
    "epoch_info.append({\n",
    "            'params': param_dict,\n",
    "            'fold_number': -1,\n",
    "            'loss': epoch_losses,\n",
    "            #'val_loss':epoch_val_losses,\n",
    "            'acc_train': epoch_accuracy,\n",
    "            #'f1_train': epoch_f1_macro,\n",
    "            'acc_val': epoch_val_accuracy,\n",
    "            #'f1_val': epoch_val_f1_macro,\n",
    "            'epoch_val_losses':epoch_val_losses,\n",
    "            'train_f1': train_f1,\n",
    "            'train_acc': train_acc,\n",
    "            'test_f1': test_f1,\n",
    "            'test_acc': test_acc,\n",
    "            'train_auc':train_auc,\n",
    "            'test_auc':test_auc,\n",
    "            'train_precision':train_precision,\n",
    "            'train_recall':train_recall,\n",
    "            'test_precision':test_precision,\n",
    "            'test_recall':test_recall,\n",
    "            'y_true_train':y_true_train,\n",
    "            'y_true_val':y_true_val, #y_true_val\n",
    "            'prediction_train': prediction_train,\n",
    "            'prediction_test': prediction_test,\n",
    "            'train_group':train_group,\n",
    "            'test_group':val_group\n",
    "            \n",
    "        })\n",
    "\n",
    "\n",
    "detailed_results.extend(epoch_info)\n",
    "\n",
    "# Convert detailed_results to a DataFrame\n",
    "detailed_results_df = pd.DataFrame(detailed_results)\n",
    "\n",
    "print(detailed_results_df)\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "\n",
    "detailed_results_df.to_csv(main_folder+'_vgg.csv')\n",
    "with open (main_folder+dt_string+'full_train_vgg.pkl', 'wb') as f:\n",
    "    pickle.dump(detailed_results_df, f)\n",
    "\n",
    "#test_predictions = model.predict(test_gen)\n",
    "\n",
    "\n",
    "#print ( train_f1, train_acc, train_auc, train_precision,train_recall)\n",
    "\n",
    "#print (test_f1, test_acc, test_auc, test_precision, test_recall)\n",
    "\n",
    "\n",
    "#model.save(f'pcg_only_finetune.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8975 validated image filenames belonging to 2 classes.\n",
      "Found 3970 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "406/406 [==============================] - 210s 508ms/step - loss: 1.5338 - Accuracy: 0.5152\n",
      "Epoch 2/20\n",
      "406/406 [==============================] - 211s 520ms/step - loss: 0.7253 - Accuracy: 0.5128\n",
      "Epoch 3/20\n",
      "406/406 [==============================] - 213s 525ms/step - loss: 0.7027 - Accuracy: 0.5048\n",
      "Epoch 4/20\n",
      "406/406 [==============================] - 218s 537ms/step - loss: 0.6909 - Accuracy: 0.5104\n",
      "Epoch 5/20\n",
      "406/406 [==============================] - 190s 468ms/step - loss: 0.6890 - Accuracy: 0.5101\n",
      "Epoch 6/20\n",
      "406/406 [==============================] - 195s 481ms/step - loss: 0.6846 - Accuracy: 0.5228\n",
      "Epoch 7/20\n",
      "406/406 [==============================] - 189s 466ms/step - loss: 0.6783 - Accuracy: 0.5210\n",
      "Epoch 8/20\n",
      "406/406 [==============================] - 185s 456ms/step - loss: 0.6756 - Accuracy: 0.5400\n",
      "Epoch 9/20\n",
      "406/406 [==============================] - 185s 455ms/step - loss: 0.6775 - Accuracy: 0.5291\n",
      "Epoch 10/20\n",
      "406/406 [==============================] - 192s 473ms/step - loss: 0.6709 - Accuracy: 0.5329\n",
      "Epoch 11/20\n",
      "406/406 [==============================] - 195s 480ms/step - loss: 0.6708 - Accuracy: 0.5419\n",
      "Epoch 12/20\n",
      "406/406 [==============================] - 194s 479ms/step - loss: 0.6652 - Accuracy: 0.5414\n",
      "Epoch 13/20\n",
      "406/406 [==============================] - 194s 478ms/step - loss: 0.6658 - Accuracy: 0.5534\n",
      "Epoch 14/20\n",
      "406/406 [==============================] - 201s 495ms/step - loss: 0.6541 - Accuracy: 0.5779\n",
      "Epoch 15/20\n",
      "406/406 [==============================] - 228s 562ms/step - loss: 0.6595 - Accuracy: 0.5697\n",
      "Epoch 16/20\n",
      "406/406 [==============================] - 224s 552ms/step - loss: 0.6608 - Accuracy: 0.5659\n",
      "Epoch 17/20\n",
      "406/406 [==============================] - 194s 477ms/step - loss: 0.6527 - Accuracy: 0.5780\n",
      "Epoch 18/20\n",
      "406/406 [==============================] - 185s 455ms/step - loss: 0.6471 - Accuracy: 0.5965\n",
      "Epoch 19/20\n",
      "406/406 [==============================] - 185s 457ms/step - loss: 0.6416 - Accuracy: 0.5766\n",
      "Epoch 20/20\n",
      "406/406 [==============================] - 185s 455ms/step - loss: 0.6427 - Accuracy: 0.6009\n"
     ]
    }
   ],
   "source": [
    "detailed_results=[]\n",
    "param_dict ={'batch_size': 32, 'epochs': 20, 'optimizer': 'adam', 'learning_rate': 1e-06, 'dropout': 0.5, 'neurons': 32, 'class_weights': False}\n",
    "param_str = str(param_dict)\n",
    "batch_size = param_dict['batch_size']\n",
    "n_epochs = param_dict['epochs']\n",
    "use_class_weights = param_dict['class_weights']\n",
    "param_dict_filtered = {x:param_dict[x] for x in param_dict.keys() if x not in ('batch_size', 'epochs', 'class_weights')}\n",
    "    \n",
    "    \n",
    "test_info = []     \n",
    "model = create_model_finetune(**param_dict_filtered)\n",
    "\n",
    "\n",
    "train_gen = train_datagen_p.flow_from_dataframe(dataframe=train_df_p,\n",
    "                                     directory=f\"./{main_folder}/train\",\n",
    "                                    target_size=(224, 224),\n",
    "                                     x_col = 'filename',\n",
    "                                     y_col = 'label',\n",
    "                                     class_mode = 'binary',\n",
    "                                     classes = [\"0\",\"1\"], shuffle=False, batch_size=batch_size,\n",
    "                                     color_mode = 'rgb' )\n",
    "\n",
    "\n",
    "\n",
    "test_gen = train_datagen_p.flow_from_dataframe(dataframe=test_df_p,\n",
    "                                 directory=f\"./{main_folder}/test\",\n",
    "                                target_size=(224, 224),\n",
    "                                 x_col = 'filename',\n",
    "                                 y_col = 'label',\n",
    "                                 class_mode = 'binary',\n",
    "                                 shuffle = False,\n",
    "                                 classes = [\"0\",\"1\"], batch_size=batch_size,\n",
    "                                 color_mode = 'rgb')\n",
    "\n",
    "#train_group = train_df_p['group']\n",
    "#score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "\n",
    "class CombinedGen():\n",
    "    def __init__(self, *gens):\n",
    "        self.gens = gens\n",
    "\n",
    "    def generate(self):\n",
    "        while True:\n",
    "            for g in self.gens:\n",
    "                yield next(g)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(g) for g in self.gens])\n",
    "\n",
    "full_data_generator=CombinedGen(train_gen, test_gen)\n",
    "\n",
    "\n",
    "if use_class_weights:\n",
    "    y_train = train_gen.classes\n",
    "\n",
    "    class_weights = compute_class_weight('balanced',\n",
    "                                             classes=np.unique(y_train),\n",
    "                                             y=y_train)\n",
    "\n",
    "\n",
    "    class_weights = {i:w for i,w in enumerate(class_weights)}\n",
    "    #score_callback = ScoreCallback(test_gen, train_gen)\n",
    "\n",
    "    #history = model.fit(train_gen, batch_size = batch_size, epochs=n_epochs, callbacks=[score_callback])\n",
    "    history = model.fit(full_data_generator.generate(), batch_size = batch_size, epochs=n_epochs,class_weight=class_weights, steps_per_epoch=len(train_gen)+len(test_gen))\n",
    "else:\n",
    "    history = model.fit(full_data_generator.generate(), batch_size = batch_size, epochs=n_epochs, steps_per_epoch=len(train_gen)+len(test_gen))\n",
    "\n",
    "#train_f1, train_acc, train_auc, train_precision, train_recall, prediction_train, y_true_train = calculate_scores(train_gen, model)\n",
    "\n",
    "#test_f1, test_acc, test_auc, test_precision, test_recall, prediction_test, y_true_val = calculate_scores(test_gen, model)\n",
    "\n",
    "#test_predictions = model.predict(test_gen)\n",
    "\n",
    "\n",
    "#print ( train_f1, train_acc, train_auc, train_precision,train_recall)\n",
    "\n",
    "#print (test_f1, test_acc, test_auc, test_precision, test_recall)\n",
    "\n",
    "\n",
    "model.save(f'pcg_only_finetune_circor.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "\n",
    "detailed_results_df.to_csv(main_folder+'_vgg.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (main_folder+dt_string+'_vgg.pkl', 'rb') as f:\n",
    "    df =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_results_df.to_csv('resultados_pcg_2016.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752502345262925"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_results_df['test_f1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1, 100):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
